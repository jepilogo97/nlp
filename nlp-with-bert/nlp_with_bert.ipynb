{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf2783a",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jepilogo97/nlp/blob/main/nlp-with-transformers/nlp_with_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "0"
   },
   "source": [
    "# NLP con BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "1"
   },
   "source": [
    "##### Jean Pierre Londoño González\n",
    "##### Mini-Proyecto de clasificación de texto con Transformers\n",
    "##### 14SEP2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "2"
   },
   "source": [
    "En este notebook se implementa un clasificador de reseñas de zapatos de amazon utilizando Bert. El dataset empleado corresponde a \n",
    "amazon-shoe-reviews, disponible en Hugging Face, el cual contiene reseñas en inglés con un respectivo score entre 0 y 4. Se realizará uso extensivo de la herramientas de Hugging Face, las cuales están especialmente desarrolladas para este tipo de tareas, incluyendo la interacción con modelos pre-entrenados.\n",
    "\n",
    "#### Referencias\n",
    "- Dataset: https://huggingface.co/datasets/excode/amazon-shoe-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "3"
   },
   "source": [
    "### 1. Importación de librerias y carga de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "4"
   },
   "source": [
    "Inicio importando las librerías necesarias para el procesamiento de lenguaje natural, la manipulación de datos y la construcción del modelo. Esto incluye NumPy y pandas para el manejo y análisis de datos; Hugging Face Datasets y Transformers para la carga de corpus y la tokenización; y PyTorch junto con PyTorch Lightning para definir, entrenar y evaluar el modelo de manera estructurada.\n",
    "\n",
    "Además, se emplean torchmetrics y scikit-learn para calcular métricas de rendimiento como precisión, matrices de confusión y reportes de clasificación, mientras que Optuna permite la optimización automática de hiperparámetros.\n",
    "\n",
    "Finalmente, tqdm facilita el seguimiento del progreso de los procesos iterativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "232f9b07-b6e9-4e9b-96fa-697d4f04b78a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "232f9b07-b6e9-4e9b-96fa-697d4f04b78a",
    "outputId": "e2bcb56f-46de-4559-ddf0-3df96a712b5b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jepil\\AppData\\Local\\Temp\\ipykernel_10276\\2396000874.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "installed_packages = [package.key for package in pkg_resources.working_set]\n",
    "IN_COLAB = 'google-colab' in installed_packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5",
    "outputId": "b23f12cf-747d-40e3-9e16-613a2e0361ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n",
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "!wget -O requirements.txt https://raw.githubusercontent.com/jepilogo97/nlp/main/nlp-with-bert/requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46aaea72-7381-4d8b-b275-be7aced0424c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\jepil\\anaconda3\\envs\\nlp\\lib\\site-packages (19.0.0)\n",
      "Collecting pyarrow\n",
      "  Using cached pyarrow-21.0.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Using cached pyarrow-21.0.0-cp310-cp310-win_amd64.whl (26.2 MB)\n",
      "Installing collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.0\n",
      "    Uninstalling pyarrow-19.0.0:\n",
      "      Successfully uninstalled pyarrow-19.0.0\n",
      "Successfully installed pyarrow-21.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6",
   "metadata": {
    "id": "6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jepil\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Procesamiento de lenguaje natural y utilidades\n",
    "import numpy as np  # Cálculo numérico y manejo de arreglos multidimensionales\n",
    "import pandas as pd  # Manipulación y análisis de datos en estructuras tipo DataFrame\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)     # Todas las filas\n",
    "pd.set_option(\"display.max_columns\", None)  # Todas las columnas\n",
    "pd.set_option(\"display.width\", None)        # No cortar líneas\n",
    "\n",
    "from datasets import Dataset, load_dataset, concatenate_datasets  # Carga y combinación de datasets de Hugging Face\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from collections import Counter  # Conteo de frecuencias de elementos (tokens, palabras, etc.)\n",
    "import os  # Manejo de rutas, archivos y operaciones del sistema de archivos\n",
    "import math  # Funciones matemáticas avanzadas (logaritmos, potencias, trigonometría, etc.)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Deep Learning con PyTorch\n",
    "import torch  # Librería principal de tensores y operaciones en GPU/CPU\n",
    "import torch.nn as nn  # Definición de capas y módulos de redes neuronales\n",
    "import torch.nn.functional as F  # Funciones de activación y operaciones matemáticas de redes\n",
    "from torch.utils.data import random_split, DataLoader, Subset  # Utilidades para crear y dividir datasets, cargar lotes y trabajar con subconjuntos\n",
    "from torchinfo import summary\n",
    "\n",
    "# Entrenamiento estructurado con PyTorch Lightning\n",
    "from pytorch_lightning import LightningModule, Trainer  # Clase base y manejador de entrenamiento de modelos\n",
    "from pytorch_lightning.loggers import TensorBoardLogger  # Registro de métricas e historial en TensorBoard\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint  # Detener entrenamiento si no mejora la métrica\n",
    "from torchmetrics import Accuracy  # Métrica de precisión para clasificación supervisada\n",
    "\n",
    "# Tipado para mayor legibilidad y validación de funciones\n",
    "from typing import Tuple, Dict, Optional  # Definición de tipos de datos para funciones y estructuras\n",
    "from enum import Enum  # Definición de enumeraciones (conjuntos de valores constantes con nombre)\n",
    "\n",
    "from tqdm.auto import tqdm  # Barra de progreso adaptable para bucles\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments  # Tokenizador automático de modelos preentrenados de Hugging Face\n",
    "from transformers.models.gpt2.tokenization_gpt2 import bytes_to_unicode  # Conversión de bytes a caracteres Unicode (usado en tokenización tipo GPT-2)\n",
    "\n",
    "from typing import Dict, Any\n",
    "import evaluate\n",
    "\n",
    "import optuna  # Optimización automática de hiperparámetros mediante búsquedas eficientes (Bayesian, TPE, etc.)\n",
    "from optuna.importance import get_param_importances\n",
    "import optuna.visualization as vis\n",
    "\n",
    "# Métricas de evaluación con Scikit-learn\n",
    "from sklearn.model_selection import train_test_split  # División de datos en conjuntos de entrenamiento y prueba\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report  # Métricas de evaluación de modelos de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "7"
   },
   "source": [
    "### 2. Cargue de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "8"
   },
   "source": [
    "Este dataset contiene 2.2k conversaciones multi-turno generadas por Llama-3.1-70B-Instruct. Se le solicitó al modelo generar una conversación sencilla, con 3 a 4 intercambios breves, entre un Usuario y un Asistente de IA sobre un tema específico.\n",
    "\n",
    "De este dataset se utilizarán específicamente las conversaciones entre el usuario y el asistente de IA, con el fin de asignarlas al tópico correspondiente. Cada ejemplo consiste en un diálogo corto multi-turno, donde el modelo debe identificar el tema principal a partir del intercambio entre ambas partes.\n",
    "\n",
    "Está disponible en el Hugging Face Hub, lo que permite descargarlo fácilmente y utilizarlo directamente en entrenamientos o pruebas de modelos de NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351,
     "referenced_widgets": [
      "8aa16845dc04408c8a426744cbc7d8d1",
      "a5bca01cac574d19af332f95f4eb99fe",
      "ae77934f5da1403ab15f634248d6c8af",
      "495c2a7f026b42e9a265ad83cfd9fa73",
      "6c316bbc8da84f7792cff714971c4559",
      "e407db182a604b5c84f9e22e7948020b",
      "b43090b95138408d8085660af4ec38b8",
      "5ac586d459764d0887342976542a88b0",
      "13713dd65054459aa05a4fefe4b802e2",
      "f81b9efabee14433a2e0f20095bc7c06",
      "d9433f6e718c4d229bee9b13717f0fb0",
      "336e63890a364c6ea8963c9100d8c984",
      "323e22c5fe0f42bf8c01e59bc1fd1c40",
      "8f683f950aa44f3da4a1305aa4f2fff5",
      "649f551703b7416eac9b6e504c4fada4",
      "3df187965ec544f99aee3d874fb62e43",
      "88c316381601462db9c54485114a2029",
      "9f886948e9df45f583ef093fd19d1c1a",
      "1dc4f05d93d9411aaf9d73e0ab59bacc",
      "7520a8c302af4f6bb3fd905f986bbf46",
      "820fa030bf3e468cbc9e3b1eab07658a",
      "e079849273e6465f8a441b812bc47bff",
      "8e2f18c2340347c5a94cd6a966d29d5c",
      "826ff0d3757045c3be5b91b2961e20b2",
      "6d5a31bd5dc74b53aa7b71a18937c9b1",
      "dd5089fad64941ffb350069a9212ba96",
      "a15095e68ea64bb5809c1f94e6a81dda",
      "a00734b3105d4065a304b1cb88e80bca",
      "1b52e23ecbcd44e5898fda886581ca9d",
      "de6d9bede2dd482fa4329a2217fa6fa0",
      "795a6fde1a054d11b2225d58d1001946",
      "3c2445411f3943b889d52c0dd5756f3c",
      "465dd895d5cb4c98b5db4bdc8a169c70",
      "7b336a959a9642f29a0b7ccd76cada48",
      "764727ed01b340b28df2a8ca324e8259",
      "3703ff978a914c49b3aa19d5efca15e6",
      "9c64695fda114b9f980b11a3042ef7b0",
      "1daadb515bfa483794e75253def9387b",
      "cd0ef32561d44aa1874cb6365ab6116e",
      "01a49a5323a54814aa868a8e8f10f2bc",
      "59f9ea80b2334c8299e48807318541fc",
      "466b2518e4a54cf085882a4e6a47f4f1",
      "b3b0f0a51fe1441fb5727dda3a0e575a",
      "c7acfc8c23df45f4b7225039b2d3a2e9",
      "9e52bfe8f3904ef3bcc1164f89e29998",
      "dd21aa80ff044821b8acec7b6a0c3a08",
      "5777e1ce266b4e20aa667b0984fa311b",
      "b956f5806e6f46a79dea13e2ead02898",
      "deab526c6c6f47a18bf082d9ef305eba",
      "a106f9da65704b60bf5673afa5974f15",
      "7133cd2b7cae43fabbb1f069b7431f80",
      "5febdf8534c346e1b4660f2e1b12a55b",
      "625d494bbc9040228d353e57f3a162ab",
      "fb5d2ee984314198a189ce1485da8014",
      "ca6c20cb089742179966a4153d10f56c"
     ]
    },
    "id": "9",
    "outputId": "96fbebfb-e16d-4abe-a7d5-b2bf39f97e3b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 90000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "dataset = load_dataset(\"excode/amazon-shoe-reviews\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "10"
   },
   "source": [
    "El dataset incluye 2 columas: El texto asociado a la reseña de los zapatos y la categoría a la que pertenece nivel de calificación). Para entrenar y validar el modelo, se dispone de 90.000 filas en el conjunto de entrenamiento y 10.000 en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "11"
   },
   "source": [
    "Concatenos los dos datasets para tener mayor cantidad de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12",
   "metadata": {
    "id": "12"
   },
   "outputs": [],
   "source": [
    "tr_dataset = dataset[\"train\"]\n",
    "te_dataset = dataset[\"test\"]\n",
    "full_dataset = concatenate_datasets([tr_dataset, te_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "13"
   },
   "source": [
    "Observemos uno de sus registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14",
    "outputId": "1ddf460c-8272-4364-a3ee-f10dd26c3f23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 3,\n",
       " 'text': 'Good shoe for office work. They will scuff very easy so be aware.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3963c18-7447-4b42-a8b4-15e1f1ee09aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Good shoe for office work. They will scuff ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I have had the Patricia II wedge in black for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Width not right and size too small if width ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I received these shoes and they weren't the sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>They began to split alone the mesh material af...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0       3  Good shoe for office work. They will scuff ver...\n",
       "1       1  I have had the Patricia II wedge in black for ...\n",
       "2       1  Width not right and size too small if width ha...\n",
       "3       0  I received these shoes and they weren't the sa...\n",
       "4       2  They began to split alone the mesh material af..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.set_format(type=\"pandas\")\n",
    "df = full_dataset.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d63b6-4c7e-406c-83b6-e874f859198f",
   "metadata": {
    "id": "957d63b6-4c7e-406c-83b6-e874f859198f"
   },
   "source": [
    "Organizamos las columnas de interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb4acdd-ae34-4c59-9ce5-43797cb784f3",
   "metadata": {
    "id": "fdb4acdd-ae34-4c59-9ce5-43797cb784f3"
   },
   "outputs": [],
   "source": [
    "df = df[[\"text\", \"labels\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dea978-374a-42cf-b9f8-e9af07ca24d9",
   "metadata": {
    "id": "22dea978-374a-42cf-b9f8-e9af07ca24d9"
   },
   "source": [
    "Ajusto el nombre de las columnas a text y category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b8f4333-3d5b-490d-a927-f08660a48cee",
   "metadata": {
    "id": "0b8f4333-3d5b-490d-a927-f08660a48cee"
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    \"text\": \"text\",\n",
    "    \"labels\": \"category\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebf5a53c-c79e-4bce-b2e4-dc50114be76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2category = dict(enumerate(np.unique(df['category'])))\n",
    "category2id = {v: k for k, v in id2category.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba926f23-32f2-4cf5-bebe-4dc4293e9f5e",
   "metadata": {
    "id": "ba926f23-32f2-4cf5-bebe-4dc4293e9f5e"
   },
   "source": [
    "Ahora observemos algunos de los registros ya ajustados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4339015d-c6f5-429b-8ea2-d75722e702ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4339015d-c6f5-429b-8ea2-d75722e702ca",
    "outputId": "62e50201-e17d-4be5-c26d-ea5bc4f8af69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good shoe for office work. They will scuff ver...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have had the Patricia II wedge in black for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Width not right and size too small if width ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I received these shoes and they weren't the sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They began to split alone the mesh material af...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  Good shoe for office work. They will scuff ver...         3\n",
       "1  I have had the Patricia II wedge in black for ...         1\n",
       "2  Width not right and size too small if width ha...         1\n",
       "3  I received these shoes and they weren't the sa...         0\n",
       "4  They began to split alone the mesh material af...         2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542aa2b-f07a-4a2a-b58a-a78f1d1522bf",
   "metadata": {},
   "source": [
    "Primero, observemos la distribución de las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebfa4837-af92-498d-a3d7-1ae5ed59371b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ebfa4837-af92-498d-a3d7-1ae5ed59371b",
    "outputId": "d90b11d0-996e-4211-dba9-6ed41a29c168"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df['category'].value_counts().sort_index().plot.barh())\n",
    "plt.title('Distribución de categorías de clases')\n",
    "plt.xlabel('Frecuencia')\n",
    "plt.ylabel('Categoría')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "16"
   },
   "source": [
    "Se encuentra que el dataset esta desbalanceado, pues algunas categorias tienes 100 registros pero otros 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b94d5e-7be9-4a71-ab48-f091786050a4",
   "metadata": {
    "id": "d0b94d5e-7be9-4a71-ab48-f091786050a4"
   },
   "source": [
    "Para efectos de la tarea solo utilizaremos las categorias que tienen una muestra suficiente y permite tener el dataset balanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52652b0d-8446-4e44-a9b8-d21e29f63e49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52652b0d-8446-4e44-a9b8-d21e29f63e49",
    "outputId": "9e482058-d640-4507-c644-fe0649dc8f7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "3    20000\n",
       "1    20000\n",
       "0    20000\n",
       "2    20000\n",
       "4    20000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee8321e1-edc9-4ed4-b1e1-2ccaec9fe0b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee8321e1-edc9-4ed4-b1e1-2ccaec9fe0b1",
    "outputId": "717ccc6a-eeed-4db0-cf35-0229c309e30a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58297b2-347f-429e-8670-e2b9868a6691",
   "metadata": {},
   "source": [
    "Observamos que es un dataset balanceado.\n",
    "\n",
    "Ahora observemos la dispersión de las palabras por cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1cd6b79-dee6-4166-80b5-b054bad58644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Palabras por Texto'] = df['text'].str.split().apply(len)\n",
    "df.boxplot('Palabras por Texto', by='category', grid=False, showfliers=False, color='black', figsize=(16, 8))\n",
    "plt.suptitle('')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d845f-43c3-4081-aa66-a1198842c64c",
   "metadata": {},
   "source": [
    "Aquí observamos mayor diversidad. Observamos que algunas clases tienden a tener más palabras que otras, e incluso algunas tienen outliers en cuanto a la longitud de los textos. Sin embargo, como nuestra tarea es de clasificación según el texto y durante el entrenamiento vamos a manejar cadenas de tamaño fijo, lo que nos debería importar más que todo es la media/mediana entre todas las categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5009200-d2f9-4cb7-808c-b9d3e47cb714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "0    22.0\n",
       "1    25.0\n",
       "2    23.0\n",
       "3    19.0\n",
       "4    12.0\n",
       "Name: Palabras por Texto, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('category')['Palabras por Texto'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bb1fba-0449-4d03-b6b7-29b0bfa6e59a",
   "metadata": {},
   "source": [
    "Como podemos observar, la mediana, que como media de tendencia central, tiende a ser más robusta que la media, nos indica que la longitud mediana de los textos entre todas las categorías tiende a rondar por las $\\approx20$ palabras. Entonces utilizaremos una longitud de texto acorde durante nuestro entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "20"
   },
   "source": [
    "### 2. Definición del Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "id": "21"
   },
   "source": [
    "Como la idea en este notebook es la de re-utilizar modelos pre-entrenados, algo a tener en cuenta es que para que esto funcione correctamente, debemos **siempre** utilizar el mismo tokenizador que se usó para entrenar el modelo. Recordemos que el tokenizador asigna un código a cada token del vocabulario, y durante la creación de los embeddings, el modelo asume esto como entrada, por lo que su usamos otro tokenizador, el modelo va a ser incapaz de derivar las relaciones semánticas apropiadas.\n",
    "\n",
    "Para esta tarea, haremos uso de un modelo BERT LARGE. El modelo puede ser encontrado [aquí](https://huggingface.co/google-bert/bert-large-uncased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba292e43-1772-421a-a4aa-a53909d09365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jepil\\anaconda3\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"google-bert/bert-large-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7f6bd-d2d3-4ac1-bc69-49a1a2cb0e99",
   "metadata": {},
   "source": [
    "Ahora sometamos a prueba el tokenizador con una frase de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcdbe5b3-815c-4b4e-bd0b-b4a02feb794c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'hello',\n",
       " 'world',\n",
       " '!',\n",
       " '!',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token = '[PAD]'\n",
    "tokenizer(\"hello world!!\", max_length=10, truncation=True, padding='max_length').tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075182ed-20f6-4cbf-b0da-66b29e9b40d7",
   "metadata": {},
   "source": [
    "Algo interesante, este tokenizador, por lo menos para las palabras de esta frase de prueba, no separa en tokens distintos estas palabras, esto es justamente la razón por la cual no deberíamos usar un tokenizador diferente con un modelo pre-entrenado, habríamos obtenido tokens diferentes y el modelo no lograría interpretar la semantica como se espera.\n",
    "\n",
    "Ahora, observemos su vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9c01980-7970-4cd2-9069-71fdb560f59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f543f8-775c-4f86-8fc2-d5c87a4053ad",
   "metadata": {},
   "source": [
    "Tenemos $30522$ tokens, es una cantidad suficientemente amplio para una tarea de NLP.\n",
    "\n",
    "Ahora, observemos otros parámetros del tokenizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d812fb32-89cf-49c7-808d-9eb1e99faab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5802449-424a-4b9b-bc8e-d5dd417b7c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb55237d-097d-4db1-8d50-8d9038ea5db6",
   "metadata": {},
   "source": [
    "Primero, observamos que el tokenizador por defecto maneja un tamaño de secuencia de $512$, mucho mayor a la longitud mediana de nuestro dataset, por lo que resulta perfecto para nuestro caso de uso. Finalmente, observamos sus salidas, las cuales serán las entradas a nuestro modelo. Como ya debemos saber, `input_ids` son los indices de los tokens y `attention_mask` es la máscara de atención cuando tenemos tokens irrelevantes (como el padding) en la cadena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "id": "28"
   },
   "source": [
    "### 3. BERT pre-entrenado como featurizer (simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "29"
   },
   "source": [
    "Ahora podemos proceder a definir el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30",
   "metadata": {
    "id": "30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shapes & Types:\n",
      "{'input_ids': (torch.Size([1, 10]), torch.int64), 'token_type_ids': (torch.Size([1, 10]), torch.int64), 'attention_mask': (torch.Size([1, 10]), torch.int64)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================================================================================================\n",
      "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Trainable\n",
      "===========================================================================================================================================================\n",
      "BertForSequenceClassification                           [1, 10]                   [1, 5]                    --                        Partial\n",
      "├─BertModel: 1-1                                        [1, 10]                   [1, 1024]                 --                        False\n",
      "│    └─BertEmbeddings: 2-1                              --                        [1, 10, 1024]             --                        False\n",
      "│    │    └─Embedding: 3-1                              [1, 10]                   [1, 10, 1024]             (31,254,528)              False\n",
      "│    │    └─Embedding: 3-2                              [1, 10]                   [1, 10, 1024]             (2,048)                   False\n",
      "│    │    └─Embedding: 3-3                              [1, 10]                   [1, 10, 1024]             (524,288)                 False\n",
      "│    │    └─LayerNorm: 3-4                              [1, 10, 1024]             [1, 10, 1024]             (2,048)                   False\n",
      "│    │    └─Dropout: 3-5                                [1, 10, 1024]             [1, 10, 1024]             --                        --\n",
      "│    └─BertEncoder: 2-2                                 [1, 10, 1024]             [1, 10, 1024]             --                        False\n",
      "│    │    └─ModuleList: 3-6                             --                        --                        (302,309,376)             False\n",
      "│    └─BertPooler: 2-3                                  [1, 10, 1024]             [1, 1024]                 --                        False\n",
      "│    │    └─Linear: 3-7                                 [1, 1024]                 [1, 1024]                 (1,049,600)               False\n",
      "│    │    └─Tanh: 3-8                                   [1, 1024]                 [1, 1024]                 --                        --\n",
      "├─Dropout: 1-2                                          [1, 1024]                 [1, 1024]                 --                        --\n",
      "├─Linear: 1-3                                           [1, 1024]                 [1, 5]                    5,125                     True\n",
      "===========================================================================================================================================================\n",
      "Total params: 335,147,013\n",
      "Trainable params: 5,125\n",
      "Non-trainable params: 335,141,888\n",
      "Total mult-adds (M): 335.15\n",
      "===========================================================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 21.96\n",
      "Params size (MB): 1340.59\n",
      "Estimated Total Size (MB): 1362.55\n",
      "===========================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "inputs = tokenizer(\"hello world!!!\", max_length=10, truncation=True, padding='max_length', return_tensors='pt')\n",
    "\n",
    "print(f\"Input Shapes & Types:\")\n",
    "print({k: (v.shape, v.dtype) for k, v in inputs.items()})\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=len(category2id)).to(device)\n",
    "\n",
    "# Congelamos los pesos del modelo base para usarlo como featurizer solamente.\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "\n",
    "input_sizes = [inputs['input_ids'].shape] * 3\n",
    "input_types = [inputs['input_ids'].dtype] * 3\n",
    "with torch.no_grad():\n",
    "    print(summary(model, input_size=input_sizes, dtypes=input_types, col_names=['input_size', 'output_size', 'num_params', 'trainable']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9db5ed5-540c-48b9-a3b3-795d65179137",
   "metadata": {},
   "source": [
    "Observamos que el modelo tiene una capa `BertModel` que corresponde al modelo pre-entrenado y finaliza con una capa lineal que sería nuestro clasificador, esta es una capa proporcionada para nosotros al momento de inicializar el modelo. Además, observamos que solamente la capa lineal que hemos especificado tiene parámetros entrenables. Entonces, a pesar de que el modelo en si tiene más de 300 millones de parámetros, solamente menos de 5 mil son entrenables.\n",
    "\n",
    "Observemos todos los modulos registrados en el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f129d01a-b5dd-4d71-b9b0-579247fe72df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'bert',\n",
       " 'bert.embeddings',\n",
       " 'bert.embeddings.word_embeddings',\n",
       " 'bert.embeddings.position_embeddings',\n",
       " 'bert.embeddings.token_type_embeddings',\n",
       " 'bert.embeddings.LayerNorm',\n",
       " 'bert.embeddings.dropout',\n",
       " 'bert.encoder',\n",
       " 'bert.encoder.layer',\n",
       " 'bert.encoder.layer.0',\n",
       " 'bert.encoder.layer.0.attention',\n",
       " 'bert.encoder.layer.0.attention.self',\n",
       " 'bert.encoder.layer.0.attention.self.query',\n",
       " 'bert.encoder.layer.0.attention.self.key',\n",
       " 'bert.encoder.layer.0.attention.self.value',\n",
       " 'bert.encoder.layer.0.attention.self.dropout',\n",
       " 'bert.encoder.layer.0.attention.output',\n",
       " 'bert.encoder.layer.0.attention.output.dense',\n",
       " 'bert.encoder.layer.0.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.0.attention.output.dropout',\n",
       " 'bert.encoder.layer.0.intermediate',\n",
       " 'bert.encoder.layer.0.intermediate.dense',\n",
       " 'bert.encoder.layer.0.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.0.output',\n",
       " 'bert.encoder.layer.0.output.dense',\n",
       " 'bert.encoder.layer.0.output.LayerNorm',\n",
       " 'bert.encoder.layer.0.output.dropout',\n",
       " 'bert.encoder.layer.1',\n",
       " 'bert.encoder.layer.1.attention',\n",
       " 'bert.encoder.layer.1.attention.self',\n",
       " 'bert.encoder.layer.1.attention.self.query',\n",
       " 'bert.encoder.layer.1.attention.self.key',\n",
       " 'bert.encoder.layer.1.attention.self.value',\n",
       " 'bert.encoder.layer.1.attention.self.dropout',\n",
       " 'bert.encoder.layer.1.attention.output',\n",
       " 'bert.encoder.layer.1.attention.output.dense',\n",
       " 'bert.encoder.layer.1.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.1.attention.output.dropout',\n",
       " 'bert.encoder.layer.1.intermediate',\n",
       " 'bert.encoder.layer.1.intermediate.dense',\n",
       " 'bert.encoder.layer.1.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.1.output',\n",
       " 'bert.encoder.layer.1.output.dense',\n",
       " 'bert.encoder.layer.1.output.LayerNorm',\n",
       " 'bert.encoder.layer.1.output.dropout',\n",
       " 'bert.encoder.layer.2',\n",
       " 'bert.encoder.layer.2.attention',\n",
       " 'bert.encoder.layer.2.attention.self',\n",
       " 'bert.encoder.layer.2.attention.self.query',\n",
       " 'bert.encoder.layer.2.attention.self.key',\n",
       " 'bert.encoder.layer.2.attention.self.value',\n",
       " 'bert.encoder.layer.2.attention.self.dropout',\n",
       " 'bert.encoder.layer.2.attention.output',\n",
       " 'bert.encoder.layer.2.attention.output.dense',\n",
       " 'bert.encoder.layer.2.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.2.attention.output.dropout',\n",
       " 'bert.encoder.layer.2.intermediate',\n",
       " 'bert.encoder.layer.2.intermediate.dense',\n",
       " 'bert.encoder.layer.2.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.2.output',\n",
       " 'bert.encoder.layer.2.output.dense',\n",
       " 'bert.encoder.layer.2.output.LayerNorm',\n",
       " 'bert.encoder.layer.2.output.dropout',\n",
       " 'bert.encoder.layer.3',\n",
       " 'bert.encoder.layer.3.attention',\n",
       " 'bert.encoder.layer.3.attention.self',\n",
       " 'bert.encoder.layer.3.attention.self.query',\n",
       " 'bert.encoder.layer.3.attention.self.key',\n",
       " 'bert.encoder.layer.3.attention.self.value',\n",
       " 'bert.encoder.layer.3.attention.self.dropout',\n",
       " 'bert.encoder.layer.3.attention.output',\n",
       " 'bert.encoder.layer.3.attention.output.dense',\n",
       " 'bert.encoder.layer.3.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.3.attention.output.dropout',\n",
       " 'bert.encoder.layer.3.intermediate',\n",
       " 'bert.encoder.layer.3.intermediate.dense',\n",
       " 'bert.encoder.layer.3.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.3.output',\n",
       " 'bert.encoder.layer.3.output.dense',\n",
       " 'bert.encoder.layer.3.output.LayerNorm',\n",
       " 'bert.encoder.layer.3.output.dropout',\n",
       " 'bert.encoder.layer.4',\n",
       " 'bert.encoder.layer.4.attention',\n",
       " 'bert.encoder.layer.4.attention.self',\n",
       " 'bert.encoder.layer.4.attention.self.query',\n",
       " 'bert.encoder.layer.4.attention.self.key',\n",
       " 'bert.encoder.layer.4.attention.self.value',\n",
       " 'bert.encoder.layer.4.attention.self.dropout',\n",
       " 'bert.encoder.layer.4.attention.output',\n",
       " 'bert.encoder.layer.4.attention.output.dense',\n",
       " 'bert.encoder.layer.4.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.4.attention.output.dropout',\n",
       " 'bert.encoder.layer.4.intermediate',\n",
       " 'bert.encoder.layer.4.intermediate.dense',\n",
       " 'bert.encoder.layer.4.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.4.output',\n",
       " 'bert.encoder.layer.4.output.dense',\n",
       " 'bert.encoder.layer.4.output.LayerNorm',\n",
       " 'bert.encoder.layer.4.output.dropout',\n",
       " 'bert.encoder.layer.5',\n",
       " 'bert.encoder.layer.5.attention',\n",
       " 'bert.encoder.layer.5.attention.self',\n",
       " 'bert.encoder.layer.5.attention.self.query',\n",
       " 'bert.encoder.layer.5.attention.self.key',\n",
       " 'bert.encoder.layer.5.attention.self.value',\n",
       " 'bert.encoder.layer.5.attention.self.dropout',\n",
       " 'bert.encoder.layer.5.attention.output',\n",
       " 'bert.encoder.layer.5.attention.output.dense',\n",
       " 'bert.encoder.layer.5.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.5.attention.output.dropout',\n",
       " 'bert.encoder.layer.5.intermediate',\n",
       " 'bert.encoder.layer.5.intermediate.dense',\n",
       " 'bert.encoder.layer.5.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.5.output',\n",
       " 'bert.encoder.layer.5.output.dense',\n",
       " 'bert.encoder.layer.5.output.LayerNorm',\n",
       " 'bert.encoder.layer.5.output.dropout',\n",
       " 'bert.encoder.layer.6',\n",
       " 'bert.encoder.layer.6.attention',\n",
       " 'bert.encoder.layer.6.attention.self',\n",
       " 'bert.encoder.layer.6.attention.self.query',\n",
       " 'bert.encoder.layer.6.attention.self.key',\n",
       " 'bert.encoder.layer.6.attention.self.value',\n",
       " 'bert.encoder.layer.6.attention.self.dropout',\n",
       " 'bert.encoder.layer.6.attention.output',\n",
       " 'bert.encoder.layer.6.attention.output.dense',\n",
       " 'bert.encoder.layer.6.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.6.attention.output.dropout',\n",
       " 'bert.encoder.layer.6.intermediate',\n",
       " 'bert.encoder.layer.6.intermediate.dense',\n",
       " 'bert.encoder.layer.6.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.6.output',\n",
       " 'bert.encoder.layer.6.output.dense',\n",
       " 'bert.encoder.layer.6.output.LayerNorm',\n",
       " 'bert.encoder.layer.6.output.dropout',\n",
       " 'bert.encoder.layer.7',\n",
       " 'bert.encoder.layer.7.attention',\n",
       " 'bert.encoder.layer.7.attention.self',\n",
       " 'bert.encoder.layer.7.attention.self.query',\n",
       " 'bert.encoder.layer.7.attention.self.key',\n",
       " 'bert.encoder.layer.7.attention.self.value',\n",
       " 'bert.encoder.layer.7.attention.self.dropout',\n",
       " 'bert.encoder.layer.7.attention.output',\n",
       " 'bert.encoder.layer.7.attention.output.dense',\n",
       " 'bert.encoder.layer.7.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.7.attention.output.dropout',\n",
       " 'bert.encoder.layer.7.intermediate',\n",
       " 'bert.encoder.layer.7.intermediate.dense',\n",
       " 'bert.encoder.layer.7.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.7.output',\n",
       " 'bert.encoder.layer.7.output.dense',\n",
       " 'bert.encoder.layer.7.output.LayerNorm',\n",
       " 'bert.encoder.layer.7.output.dropout',\n",
       " 'bert.encoder.layer.8',\n",
       " 'bert.encoder.layer.8.attention',\n",
       " 'bert.encoder.layer.8.attention.self',\n",
       " 'bert.encoder.layer.8.attention.self.query',\n",
       " 'bert.encoder.layer.8.attention.self.key',\n",
       " 'bert.encoder.layer.8.attention.self.value',\n",
       " 'bert.encoder.layer.8.attention.self.dropout',\n",
       " 'bert.encoder.layer.8.attention.output',\n",
       " 'bert.encoder.layer.8.attention.output.dense',\n",
       " 'bert.encoder.layer.8.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.8.attention.output.dropout',\n",
       " 'bert.encoder.layer.8.intermediate',\n",
       " 'bert.encoder.layer.8.intermediate.dense',\n",
       " 'bert.encoder.layer.8.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.8.output',\n",
       " 'bert.encoder.layer.8.output.dense',\n",
       " 'bert.encoder.layer.8.output.LayerNorm',\n",
       " 'bert.encoder.layer.8.output.dropout',\n",
       " 'bert.encoder.layer.9',\n",
       " 'bert.encoder.layer.9.attention',\n",
       " 'bert.encoder.layer.9.attention.self',\n",
       " 'bert.encoder.layer.9.attention.self.query',\n",
       " 'bert.encoder.layer.9.attention.self.key',\n",
       " 'bert.encoder.layer.9.attention.self.value',\n",
       " 'bert.encoder.layer.9.attention.self.dropout',\n",
       " 'bert.encoder.layer.9.attention.output',\n",
       " 'bert.encoder.layer.9.attention.output.dense',\n",
       " 'bert.encoder.layer.9.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.9.attention.output.dropout',\n",
       " 'bert.encoder.layer.9.intermediate',\n",
       " 'bert.encoder.layer.9.intermediate.dense',\n",
       " 'bert.encoder.layer.9.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.9.output',\n",
       " 'bert.encoder.layer.9.output.dense',\n",
       " 'bert.encoder.layer.9.output.LayerNorm',\n",
       " 'bert.encoder.layer.9.output.dropout',\n",
       " 'bert.encoder.layer.10',\n",
       " 'bert.encoder.layer.10.attention',\n",
       " 'bert.encoder.layer.10.attention.self',\n",
       " 'bert.encoder.layer.10.attention.self.query',\n",
       " 'bert.encoder.layer.10.attention.self.key',\n",
       " 'bert.encoder.layer.10.attention.self.value',\n",
       " 'bert.encoder.layer.10.attention.self.dropout',\n",
       " 'bert.encoder.layer.10.attention.output',\n",
       " 'bert.encoder.layer.10.attention.output.dense',\n",
       " 'bert.encoder.layer.10.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.10.attention.output.dropout',\n",
       " 'bert.encoder.layer.10.intermediate',\n",
       " 'bert.encoder.layer.10.intermediate.dense',\n",
       " 'bert.encoder.layer.10.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.10.output',\n",
       " 'bert.encoder.layer.10.output.dense',\n",
       " 'bert.encoder.layer.10.output.LayerNorm',\n",
       " 'bert.encoder.layer.10.output.dropout',\n",
       " 'bert.encoder.layer.11',\n",
       " 'bert.encoder.layer.11.attention',\n",
       " 'bert.encoder.layer.11.attention.self',\n",
       " 'bert.encoder.layer.11.attention.self.query',\n",
       " 'bert.encoder.layer.11.attention.self.key',\n",
       " 'bert.encoder.layer.11.attention.self.value',\n",
       " 'bert.encoder.layer.11.attention.self.dropout',\n",
       " 'bert.encoder.layer.11.attention.output',\n",
       " 'bert.encoder.layer.11.attention.output.dense',\n",
       " 'bert.encoder.layer.11.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.11.attention.output.dropout',\n",
       " 'bert.encoder.layer.11.intermediate',\n",
       " 'bert.encoder.layer.11.intermediate.dense',\n",
       " 'bert.encoder.layer.11.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.11.output',\n",
       " 'bert.encoder.layer.11.output.dense',\n",
       " 'bert.encoder.layer.11.output.LayerNorm',\n",
       " 'bert.encoder.layer.11.output.dropout',\n",
       " 'bert.encoder.layer.12',\n",
       " 'bert.encoder.layer.12.attention',\n",
       " 'bert.encoder.layer.12.attention.self',\n",
       " 'bert.encoder.layer.12.attention.self.query',\n",
       " 'bert.encoder.layer.12.attention.self.key',\n",
       " 'bert.encoder.layer.12.attention.self.value',\n",
       " 'bert.encoder.layer.12.attention.self.dropout',\n",
       " 'bert.encoder.layer.12.attention.output',\n",
       " 'bert.encoder.layer.12.attention.output.dense',\n",
       " 'bert.encoder.layer.12.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.12.attention.output.dropout',\n",
       " 'bert.encoder.layer.12.intermediate',\n",
       " 'bert.encoder.layer.12.intermediate.dense',\n",
       " 'bert.encoder.layer.12.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.12.output',\n",
       " 'bert.encoder.layer.12.output.dense',\n",
       " 'bert.encoder.layer.12.output.LayerNorm',\n",
       " 'bert.encoder.layer.12.output.dropout',\n",
       " 'bert.encoder.layer.13',\n",
       " 'bert.encoder.layer.13.attention',\n",
       " 'bert.encoder.layer.13.attention.self',\n",
       " 'bert.encoder.layer.13.attention.self.query',\n",
       " 'bert.encoder.layer.13.attention.self.key',\n",
       " 'bert.encoder.layer.13.attention.self.value',\n",
       " 'bert.encoder.layer.13.attention.self.dropout',\n",
       " 'bert.encoder.layer.13.attention.output',\n",
       " 'bert.encoder.layer.13.attention.output.dense',\n",
       " 'bert.encoder.layer.13.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.13.attention.output.dropout',\n",
       " 'bert.encoder.layer.13.intermediate',\n",
       " 'bert.encoder.layer.13.intermediate.dense',\n",
       " 'bert.encoder.layer.13.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.13.output',\n",
       " 'bert.encoder.layer.13.output.dense',\n",
       " 'bert.encoder.layer.13.output.LayerNorm',\n",
       " 'bert.encoder.layer.13.output.dropout',\n",
       " 'bert.encoder.layer.14',\n",
       " 'bert.encoder.layer.14.attention',\n",
       " 'bert.encoder.layer.14.attention.self',\n",
       " 'bert.encoder.layer.14.attention.self.query',\n",
       " 'bert.encoder.layer.14.attention.self.key',\n",
       " 'bert.encoder.layer.14.attention.self.value',\n",
       " 'bert.encoder.layer.14.attention.self.dropout',\n",
       " 'bert.encoder.layer.14.attention.output',\n",
       " 'bert.encoder.layer.14.attention.output.dense',\n",
       " 'bert.encoder.layer.14.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.14.attention.output.dropout',\n",
       " 'bert.encoder.layer.14.intermediate',\n",
       " 'bert.encoder.layer.14.intermediate.dense',\n",
       " 'bert.encoder.layer.14.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.14.output',\n",
       " 'bert.encoder.layer.14.output.dense',\n",
       " 'bert.encoder.layer.14.output.LayerNorm',\n",
       " 'bert.encoder.layer.14.output.dropout',\n",
       " 'bert.encoder.layer.15',\n",
       " 'bert.encoder.layer.15.attention',\n",
       " 'bert.encoder.layer.15.attention.self',\n",
       " 'bert.encoder.layer.15.attention.self.query',\n",
       " 'bert.encoder.layer.15.attention.self.key',\n",
       " 'bert.encoder.layer.15.attention.self.value',\n",
       " 'bert.encoder.layer.15.attention.self.dropout',\n",
       " 'bert.encoder.layer.15.attention.output',\n",
       " 'bert.encoder.layer.15.attention.output.dense',\n",
       " 'bert.encoder.layer.15.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.15.attention.output.dropout',\n",
       " 'bert.encoder.layer.15.intermediate',\n",
       " 'bert.encoder.layer.15.intermediate.dense',\n",
       " 'bert.encoder.layer.15.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.15.output',\n",
       " 'bert.encoder.layer.15.output.dense',\n",
       " 'bert.encoder.layer.15.output.LayerNorm',\n",
       " 'bert.encoder.layer.15.output.dropout',\n",
       " 'bert.encoder.layer.16',\n",
       " 'bert.encoder.layer.16.attention',\n",
       " 'bert.encoder.layer.16.attention.self',\n",
       " 'bert.encoder.layer.16.attention.self.query',\n",
       " 'bert.encoder.layer.16.attention.self.key',\n",
       " 'bert.encoder.layer.16.attention.self.value',\n",
       " 'bert.encoder.layer.16.attention.self.dropout',\n",
       " 'bert.encoder.layer.16.attention.output',\n",
       " 'bert.encoder.layer.16.attention.output.dense',\n",
       " 'bert.encoder.layer.16.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.16.attention.output.dropout',\n",
       " 'bert.encoder.layer.16.intermediate',\n",
       " 'bert.encoder.layer.16.intermediate.dense',\n",
       " 'bert.encoder.layer.16.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.16.output',\n",
       " 'bert.encoder.layer.16.output.dense',\n",
       " 'bert.encoder.layer.16.output.LayerNorm',\n",
       " 'bert.encoder.layer.16.output.dropout',\n",
       " 'bert.encoder.layer.17',\n",
       " 'bert.encoder.layer.17.attention',\n",
       " 'bert.encoder.layer.17.attention.self',\n",
       " 'bert.encoder.layer.17.attention.self.query',\n",
       " 'bert.encoder.layer.17.attention.self.key',\n",
       " 'bert.encoder.layer.17.attention.self.value',\n",
       " 'bert.encoder.layer.17.attention.self.dropout',\n",
       " 'bert.encoder.layer.17.attention.output',\n",
       " 'bert.encoder.layer.17.attention.output.dense',\n",
       " 'bert.encoder.layer.17.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.17.attention.output.dropout',\n",
       " 'bert.encoder.layer.17.intermediate',\n",
       " 'bert.encoder.layer.17.intermediate.dense',\n",
       " 'bert.encoder.layer.17.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.17.output',\n",
       " 'bert.encoder.layer.17.output.dense',\n",
       " 'bert.encoder.layer.17.output.LayerNorm',\n",
       " 'bert.encoder.layer.17.output.dropout',\n",
       " 'bert.encoder.layer.18',\n",
       " 'bert.encoder.layer.18.attention',\n",
       " 'bert.encoder.layer.18.attention.self',\n",
       " 'bert.encoder.layer.18.attention.self.query',\n",
       " 'bert.encoder.layer.18.attention.self.key',\n",
       " 'bert.encoder.layer.18.attention.self.value',\n",
       " 'bert.encoder.layer.18.attention.self.dropout',\n",
       " 'bert.encoder.layer.18.attention.output',\n",
       " 'bert.encoder.layer.18.attention.output.dense',\n",
       " 'bert.encoder.layer.18.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.18.attention.output.dropout',\n",
       " 'bert.encoder.layer.18.intermediate',\n",
       " 'bert.encoder.layer.18.intermediate.dense',\n",
       " 'bert.encoder.layer.18.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.18.output',\n",
       " 'bert.encoder.layer.18.output.dense',\n",
       " 'bert.encoder.layer.18.output.LayerNorm',\n",
       " 'bert.encoder.layer.18.output.dropout',\n",
       " 'bert.encoder.layer.19',\n",
       " 'bert.encoder.layer.19.attention',\n",
       " 'bert.encoder.layer.19.attention.self',\n",
       " 'bert.encoder.layer.19.attention.self.query',\n",
       " 'bert.encoder.layer.19.attention.self.key',\n",
       " 'bert.encoder.layer.19.attention.self.value',\n",
       " 'bert.encoder.layer.19.attention.self.dropout',\n",
       " 'bert.encoder.layer.19.attention.output',\n",
       " 'bert.encoder.layer.19.attention.output.dense',\n",
       " 'bert.encoder.layer.19.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.19.attention.output.dropout',\n",
       " 'bert.encoder.layer.19.intermediate',\n",
       " 'bert.encoder.layer.19.intermediate.dense',\n",
       " 'bert.encoder.layer.19.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.19.output',\n",
       " 'bert.encoder.layer.19.output.dense',\n",
       " 'bert.encoder.layer.19.output.LayerNorm',\n",
       " 'bert.encoder.layer.19.output.dropout',\n",
       " 'bert.encoder.layer.20',\n",
       " 'bert.encoder.layer.20.attention',\n",
       " 'bert.encoder.layer.20.attention.self',\n",
       " 'bert.encoder.layer.20.attention.self.query',\n",
       " 'bert.encoder.layer.20.attention.self.key',\n",
       " 'bert.encoder.layer.20.attention.self.value',\n",
       " 'bert.encoder.layer.20.attention.self.dropout',\n",
       " 'bert.encoder.layer.20.attention.output',\n",
       " 'bert.encoder.layer.20.attention.output.dense',\n",
       " 'bert.encoder.layer.20.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.20.attention.output.dropout',\n",
       " 'bert.encoder.layer.20.intermediate',\n",
       " 'bert.encoder.layer.20.intermediate.dense',\n",
       " 'bert.encoder.layer.20.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.20.output',\n",
       " 'bert.encoder.layer.20.output.dense',\n",
       " 'bert.encoder.layer.20.output.LayerNorm',\n",
       " 'bert.encoder.layer.20.output.dropout',\n",
       " 'bert.encoder.layer.21',\n",
       " 'bert.encoder.layer.21.attention',\n",
       " 'bert.encoder.layer.21.attention.self',\n",
       " 'bert.encoder.layer.21.attention.self.query',\n",
       " 'bert.encoder.layer.21.attention.self.key',\n",
       " 'bert.encoder.layer.21.attention.self.value',\n",
       " 'bert.encoder.layer.21.attention.self.dropout',\n",
       " 'bert.encoder.layer.21.attention.output',\n",
       " 'bert.encoder.layer.21.attention.output.dense',\n",
       " 'bert.encoder.layer.21.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.21.attention.output.dropout',\n",
       " 'bert.encoder.layer.21.intermediate',\n",
       " 'bert.encoder.layer.21.intermediate.dense',\n",
       " 'bert.encoder.layer.21.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.21.output',\n",
       " 'bert.encoder.layer.21.output.dense',\n",
       " 'bert.encoder.layer.21.output.LayerNorm',\n",
       " 'bert.encoder.layer.21.output.dropout',\n",
       " 'bert.encoder.layer.22',\n",
       " 'bert.encoder.layer.22.attention',\n",
       " 'bert.encoder.layer.22.attention.self',\n",
       " 'bert.encoder.layer.22.attention.self.query',\n",
       " 'bert.encoder.layer.22.attention.self.key',\n",
       " 'bert.encoder.layer.22.attention.self.value',\n",
       " 'bert.encoder.layer.22.attention.self.dropout',\n",
       " 'bert.encoder.layer.22.attention.output',\n",
       " 'bert.encoder.layer.22.attention.output.dense',\n",
       " 'bert.encoder.layer.22.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.22.attention.output.dropout',\n",
       " 'bert.encoder.layer.22.intermediate',\n",
       " 'bert.encoder.layer.22.intermediate.dense',\n",
       " 'bert.encoder.layer.22.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.22.output',\n",
       " 'bert.encoder.layer.22.output.dense',\n",
       " 'bert.encoder.layer.22.output.LayerNorm',\n",
       " 'bert.encoder.layer.22.output.dropout',\n",
       " 'bert.encoder.layer.23',\n",
       " 'bert.encoder.layer.23.attention',\n",
       " 'bert.encoder.layer.23.attention.self',\n",
       " 'bert.encoder.layer.23.attention.self.query',\n",
       " 'bert.encoder.layer.23.attention.self.key',\n",
       " 'bert.encoder.layer.23.attention.self.value',\n",
       " 'bert.encoder.layer.23.attention.self.dropout',\n",
       " 'bert.encoder.layer.23.attention.output',\n",
       " 'bert.encoder.layer.23.attention.output.dense',\n",
       " 'bert.encoder.layer.23.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.23.attention.output.dropout',\n",
       " 'bert.encoder.layer.23.intermediate',\n",
       " 'bert.encoder.layer.23.intermediate.dense',\n",
       " 'bert.encoder.layer.23.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.23.output',\n",
       " 'bert.encoder.layer.23.output.dense',\n",
       " 'bert.encoder.layer.23.output.LayerNorm',\n",
       " 'bert.encoder.layer.23.output.dropout',\n",
       " 'bert.pooler',\n",
       " 'bert.pooler.dense',\n",
       " 'bert.pooler.activation',\n",
       " 'dropout',\n",
       " 'classifier']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = [m for m, _ in model.named_modules()]\n",
    "modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5709e8f-5ded-459d-86fb-f199e87c239c",
   "metadata": {},
   "source": [
    "Observamos que la capa final es efectivamente el clasificador. Ahora hagamos una prueba pasando un dummy input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "280fb038-7a8d-4bc4-ad03-a0949e1513fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logits': torch.Size([1, 5])}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "print({k: v.shape for k, v in outputs.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "577303e0-45f8-47d3-8ed9-941f241191a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0803, -0.3081, -0.1441,  0.3440, -0.0736]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89147c92-b29a-4c43-9abc-b28df2d7d6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=5, bias=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0f03f-cdd2-471e-bb27-1105ba1f204f",
   "metadata": {},
   "source": [
    "Observamos que tras invocar el modelo, en efecto, obtenemos una salida de 5 dimensiones, correspondientes al número de clases.\n",
    "\n",
    "Ahora preparemos los datos para el entrenamiento.\n",
    "\n",
    "Hugging Face Datasets convenientemente implementa una función para hacer el train-test splig en nuestro dataset y automáticamente creará nuevas llaves en el mismo para diferenciarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d4120fb-674d-4e48-b38a-37ca79bda01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "665cb1c8-5bd6-4ad1-ba99-c548cc593387",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = dataset.train_test_split(train_size=0.8)\n",
    "validation_dataset = training_dataset['test'].train_test_split(train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ddf3a65-e35d-4994-b853-11cd29d40198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'category', 'Palabras por Texto'],\n",
       "        num_rows: 80000\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'category', 'Palabras por Texto'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'category', 'Palabras por Texto'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = DatasetDict({\n",
    "    'train': training_dataset['train'],\n",
    "    'val': validation_dataset['train'],\n",
    "    'test': validation_dataset['test'],\n",
    "})\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8709f89d-54c9-42ca-ab6a-8217f55e2982",
   "metadata": {},
   "source": [
    "Tenemos nuestros tres conjuntos, sin embargo, esto es la información cruda, debemos preparar los datos para el modelo, lo gual incluye tokenizar y convertir las categorías a ids. Preparamos entonces unas funciones utilitarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d3bac87-0acc-44d3-95e3-17b1d39e1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(max_len):\n",
    "    def _preprocess_function(examples):\n",
    "        return tokenizer(examples['text'], max_length=max_len, truncation=True, padding='max_length')\n",
    "    return _preprocess_function\n",
    "\n",
    "def tokenize(max_len: int = 8):\n",
    "    def _tokenize(batch):\n",
    "        return tokenizer(batch['text'], max_length=max_len, truncation=True, padding='max_length')\n",
    "    return _tokenize\n",
    "\n",
    "def category_names_2_ids(batch):\n",
    "    batch['label'] = category2id[batch['category']]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811907e2-f653-460c-b0a7-b7999c76510f",
   "metadata": {},
   "source": [
    "Y procedemos a invocarlas. Nótese que para la tokenización, estamos forzando a que las cadenas sean de 20 tokens, según el análisis que hemos hecho anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8133e1a-9ba3-4a7e-9426-8f1867954c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 80000/80000 [00:14<00:00, 5513.74 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:02<00:00, 4945.23 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:01<00:00, 5685.29 examples/s]\n",
      "Map: 100%|██████████| 80000/80000 [00:07<00:00, 10489.40 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 12465.94 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:01<00:00, 9954.99 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'category', 'Palabras por Texto', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 80000\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'category', 'Palabras por Texto', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'category', 'Palabras por Texto', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = new_dataset.map(preprocess_function(max_len=20), batched=True)\n",
    "tokenized_dataset = tokenized_dataset.map(category_names_2_ids)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0bf6ea-a2bb-4276-b355-9e2083eda65f",
   "metadata": {
    "id": "6e0bf6ea-a2bb-4276-b355-9e2083eda65f"
   },
   "source": [
    "### 4. Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56251dff-d7d1-42dc-82d8-4cafa039d2dd",
   "metadata": {
    "id": "56251dff-d7d1-42dc-82d8-4cafa039d2dd"
   },
   "source": [
    "Ahora procederemos al entrenamiento. Aquí harémos uso de las API de HuggingFace directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7b6c2ae-c471-467f-a22d-08363a8e36b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'eval_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m logging_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokenized_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Definimos los parámetros globales de entrenamiento\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./hf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtensorboard\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Y definimos el entrenador, especificando el modelo, datasets y el tokenizador\u001b[39;00m\n\u001b[0;32m     37\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     38\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     39\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[0;32m     44\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'eval_strategy'"
     ]
    }
   ],
   "source": [
    "# Definimos la función métrica de calidad\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(pred) -> Dict[str, Any]:\n",
    "    \"\"\"compute metrics\n",
    "\n",
    "    Esta función será invocada en\n",
    "    cada epoca y la utilizaremos para\n",
    "    calcular la métrica de calidad.\n",
    "    \"\"\" \n",
    "    labels = pred.label_ids \n",
    "    preds = pred.predictions.argmax(-1) \n",
    "    # Retorna un diccionario como {'nombre-metrica': valor}\n",
    "    acc = accuracy.compute(predictions=preds, references=labels)\n",
    "    return acc\n",
    "\n",
    "\n",
    "batch_size = 8 if IN_COLAB else 4\n",
    "logging_steps = len(tokenized_dataset['train']) // batch_size\n",
    "# Definimos los parámetros globales de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./hf',\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    report_to='tensorboard'\n",
    ")\n",
    "\n",
    "# Y definimos el entrenador, especificando el modelo, datasets y el tokenizador\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33c702e-9701-42d3-8bb2-d85288ad7a29",
   "metadata": {},
   "source": [
    "Con esto nos basta para ejecutar el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1854639-dec6-4442-a802-dd3f765c19a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeb40a8-7e3f-4e85-9e3b-5b91ced7e6c6",
   "metadata": {},
   "source": [
    "Algo importante a resaltar es que fueron necesarias solo 2 iteraciones para alcanzar un ta tasa de correctitud $\\approx 79%$, algo que con el modelo de transformers crudo nos costó muchas más iteraciones. Esto demuestra la importancia de partir de modelos pre-entrenados para este tipo de tareas.\n",
    "\n",
    "Una ventaja adicional de Hugging Face transformers, es que publica automáticamente el progreso del entrenamiento a tensorboard, en el directorio que hemos especificado. Observemos entonces el proceso de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3153d-1f0e-41f8-a60a-c973777829d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15d19a-3664-4d99-b023-89325b6c6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir hf/runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d05849-f3d3-42e2-af96-7a5242b91486",
   "metadata": {},
   "source": [
    "Y ahora evaluemos el modelo en el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9ac2a-d487-4fe9-bd5b-41b45040f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "trainer.evaluate(tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d4146-ba4f-497e-aaf6-0a8d530cb93f",
   "metadata": {},
   "source": [
    "Hemos alcanzado una correctitud del $\\approx 80\\%$, lo cual, nuevamente, en comparación con el modelo de transformers crudo nos costó muchisimo más lograr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {
    "id": "45"
   },
   "source": [
    "### 5. Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "id": "46"
   },
   "source": [
    "Ahora, hagamos predicciónes con el modelo y observemos los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a6370-231d-4259-86b8-18af32f753ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_dataset['test'])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51209e3b-c745-4d1f-8586-5450e64e0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "test_set = tokenized_dataset['test']\n",
    "test_set = test_set.add_column('prediction_label', predicted_labels)\n",
    "test_set = test_set.add_column('prediction', list(map(lambda label: id2category[label], predicted_labels)))\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b0ef56-62c6-49f6-b6ef-e2d31d060886",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['text', 'label', 'prediction_label', 'category', 'prediction']\n",
    "test_set.set_format('pandas', columns=columns)\n",
    "df = test_set.to_pandas()[columns]\n",
    "df.style.set_table_styles(\n",
    "    [\n",
    "        {'selector': 'td', 'props': [('word-wrap', 'break-word')]}\n",
    "    ]\n",
    ")\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d769f-ecac-45ac-98cf-ad290d16cec9",
   "metadata": {},
   "source": [
    "Los resultados no lucen nada mal, aún se cometen un par de errores, pero de resto, parece bastante aceptable. Observemos los errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e7bac9-efe4-4a74-92eb-7094be6ee21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = df[df['label'] != df['prediction_label']]\n",
    "errors.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018940e5-bf64-400f-ac48-ece7f8990e4e",
   "metadata": {},
   "source": [
    "Los errores parece que son mucho más interesantes que en nuestro mdelo pasado.\n",
    "\n",
    "Los errores parecen algo mucho más genuino, economía y política son categorías que tienen algo de superposición entre si, al igual que motor y deportes, según sea el caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e550d87-0e0e-47ed-91ad-e5267dc39a39",
   "metadata": {},
   "source": [
    "## Usando una capa más especializada como clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5060f49-28bf-458f-8eaa-3a265eeb392a",
   "metadata": {},
   "source": [
    "Quizás podemos hacerlo mejor, hemos observado que por defecto, cuando cargamos la clase, Hugging Face nos da un clasificador muy simple, solo una capa lineal. Pero podemos utilizar un clasificador más complejo que definamos nosotros. Esta técnica seguiría utilizando el resto del modelo como featurizer, pero ahora añadimos complejidad a la capa de clasificación en búsqueda de una mejor calidad en los resutlados.\n",
    "\n",
    "Entonces, volvemos a cargar el modelo tal como hemos hecho antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e0a67-db42-496f-b82d-4cbf6e1ec22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=len(category2id)).to(device)\n",
    "\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "  \n",
    "input_sizes = [inputs['input_ids'].shape] * 3\n",
    "input_types = [inputs['input_ids'].dtype] * 3\n",
    "with torch.no_grad():\n",
    "    print(summary(model, input_size=input_sizes, dtypes=input_types, col_names=['input_size', 'output_size', 'num_params', 'trainable']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45410f63-4ead-4c37-9dfe-f0726f46ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d05ff-b0a8-46b5-b710-2aa3724fbf5f",
   "metadata": {},
   "source": [
    "### Definiendo un clasificador propio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd221a7-161f-4f8b-9d91-c29f0d2b2db4",
   "metadata": {},
   "source": [
    "Podemos definir cualquier tipo de clasificador que se nos ocurra, siempre que se ajuste a las entradas y salidas del clasificador existente. Vamos a utilizar por ejemplo la misma capa lineal que definimos en el notebook anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb20e88-dd4b-42db-ac0c-fe807af707b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Sequential(\n",
    "    nn.Linear(768, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 12),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "# simplemente reemplazamos el clasificador existente por el nuestro:\n",
    "model.classifier = classifier\n",
    "with torch.no_grad():\n",
    "    print(summary(model, input_size=input_sizes, dtypes=input_types, col_names=['input_size', 'output_size', 'num_params', 'trainable']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa03fe-9765-447b-8218-121a00ecd8a5",
   "metadata": {},
   "source": [
    "Observamos que nuestro modelo ya tiene más parámetros para entrenar, producto de nuestro nuevo clasificador.\n",
    "\n",
    "Procedemos a definir nuevamente el entrenador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc58efb1-a0b5-4a9c-9d56-26f5319e8e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f07ef3-f52c-4fe0-b533-b0e4f81d25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b1793-49a5-4ca5-8f3d-bb65402dd617",
   "metadata": {},
   "source": [
    "Y evaluamos el resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88525a94-789d-45ee-bec1-3b1c14d38269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "trainer.evaluate(tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ded31e-b845-4d2e-b0d7-9d76817723f6",
   "metadata": {},
   "source": [
    "Hemos obtenido una ligera mejora en nuestro modelo, lo cual sugiere que nuestro clasificador más complejo contribuye a una mayor calidad de los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db1cf2-54d1-4a12-b5f4-a044358e53e2",
   "metadata": {},
   "source": [
    "## Fine Tuning con BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985ef87-0254-4e5c-8639-af0873b8a7f8",
   "metadata": {},
   "source": [
    "Para terminar, ahora harémos fine tuning, es decir, vamos a dejar libres todas las capas del modelo base para que todas calculen gradiente y entrenen sobre nuestra tarea específica.\n",
    "\n",
    "En este caso entonces no necesitamos modificar nada del modelo original, podemos instanciarlo y proceder directamente al entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98aaae4-87c6-40e2-9f7d-33a5d06b6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=len(category2id)).to(device)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db88e36-5d07-498f-991b-0bfb0f24144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1278e6-c83e-4fce-a41f-481a96c67ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "trainer.evaluate(tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401244d-408c-4537-8b80-4596fe7042aa",
   "metadata": {},
   "source": [
    "Hemos alcanzado una correctitud superior al $\\approx 90\\%$ en el conjunto de prueba!\n",
    "\n",
    "Con fine tuning, todas las capas del modelo ajustarán sus parámetros en respuesta al proceso de entrenamiento, por lo que es natural que la calidad de los resultados se incremente significativamente. Sin embargo, no hay que abusar del fine tuning ya que tiende a hacer overfitting al conjunto con el que se entrena, por eso también es recomendable no entrenarlo demasiado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {
    "id": "54"
   },
   "source": [
    "### 12. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {
    "id": "55"
   },
   "source": [
    "#### Eficacia del flujo de análisis\n",
    "\n",
    "- Se evaluó el uso de modelos de lenguaje pre-entrenados, observándose mejoras notables tanto en la calidad de los resultados como en los tiempos de entrenamiento y en el esfuerzo de implementación.\n",
    "\n",
    "- El enfoque de transfer learning o fine tuning permite aprovechar representaciones previamente aprendidas, evitando el alto costo de entrenar un modelo de lenguaje desde cero.\n",
    "\n",
    "#### Rendimiento del modelo\n",
    "\n",
    "- Comenzar con un modelo pre-entrenado ofrece una base sólida para la tarea específica, reduciendo significativamente el tiempo de entrenamiento y los recursos computacionales requeridos, a la vez que mantiene un alto nivel de desempeño.\n",
    "\n",
    "- El fine tuning suele brindar un rendimiento superior frente a otras variantes de transfer learning; sin embargo, su conveniencia depende de la disponibilidad de datos, capacidad de cómputo y tiempo.\n",
    "\n",
    "#### Limitaciones observadas\n",
    "\n",
    "- No siempre se cuenta con recursos suficientes (datos, GPU o presupuesto) para realizar un fine tuning completo.\n",
    "\n",
    "- En entornos de despliegue con restricciones de hardware (por ejemplo, sin GPU), puede ser más factible optar por métodos de transferencia menos costosos o incluso modelos clásicos.\n",
    "\n",
    "#### Áreas de mejora\n",
    "\n",
    "- Explorar estrategias de optimización que equilibren precisión y eficiencia, como el uso de modelos más ligeros o técnicas de compresión (distillation, pruning) para escenarios con recursos limitados.\n",
    "\n",
    "- Analizar casos en los que un modelo pre-entrenado no cubra adecuadamente el dominio o idioma de la tarea —por ejemplo, un contexto legal altamente especializado o lenguas poco representadas— para determinar si es necesario entrenar un modelo desde cero o complementar el corpus.\n",
    "\n",
    "#### Valor práctico\n",
    "\n",
    "- El uso de modelos pre-entrenados con transfer learning o fine tuning valida su viabilidad como enfoque inicial para la mayoría de los proyectos de NLP, al ofrecer una relación óptima entre costo, tiempo y calidad.\n",
    "\n",
    "- Este enfoque sirve como punto de partida flexible: permite escalar hacia arquitecturas más sofisticadas o, cuando la tarea es completamente novedosa, evaluar el entrenamiento de un modelo propio solo si el contexto lo justifica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1089b9-ae81-4ae0-91ec-d323c7c84352",
   "metadata": {
    "id": "4b1089b9-ae81-4ae0-91ec-d323c7c84352"
   },
   "source": [
    "### 13. Apendice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "636a28e4-5609-4f01-b6f9-60343d6cb413",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "636a28e4-5609-4f01-b6f9-60343d6cb413",
    "outputId": "15317e8e-0bad-448c-cedf-420b5c363083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy==2.1.3\n",
      "pandas==2.3.1\n",
      "datasets==3.3.2\n",
      "torch==2.6.0\n",
      "pytorch-lightning==2.5.0.post0\n",
      "torchmetrics==1.2.1\n",
      "tqdm==4.67.1\n",
      "transformers==4.39.3\n",
      "scikit-learn==1.6.1\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "libs = [\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"datasets\",\n",
    "    \"torch\",\n",
    "    \"pytorch-lightning\",\n",
    "    \"torchmetrics\",\n",
    "    \"tqdm\",\n",
    "    \"transformers\",\n",
    "    \"scikit-learn\"\n",
    "]\n",
    "\n",
    "for lib in libs:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(lib).version\n",
    "        print(f\"{lib}=={version}\")\n",
    "    except Exception:\n",
    "        print(f\"{lib}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646eaeca-8b47-46c4-9995-16c1f2ceb0e0",
   "metadata": {
    "id": "646eaeca-8b47-46c4-9995-16c1f2ceb0e0"
   },
   "outputs": [],
   "source": [
    " ## Solo correr en local\n",
    "\n",
    "# import nbformat\n",
    "\n",
    "## Cargar notebook\n",
    "# with open(\"nlp_with_transformers.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    # nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "## Eliminar widgets corruptos si existen\n",
    "# if \"widgets\" in nb[\"metadata\"]:\n",
    "    # del nb[\"metadata\"][\"widgets\"]\n",
    "\n",
    "## Guardar reparado\n",
    "# with open(\"nlp_with_transformers.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
    "    # nbformat.write(nb, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
