{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c904a2b0",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jepilogo97/nlp/blob/main/nlp-with-bert/nlp_with_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "0"
   },
   "source": [
    "# NLP con GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "1"
   },
   "source": [
    "##### Jean Pierre Londoño González\n",
    "##### Mini-Proyecto de clasificación de texto usando GPT\n",
    "##### 21SEP2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "2"
   },
   "source": [
    "En este notebook harémos uso de un modelo GPT neo de 2.7B que utilizaremos para generar texto a partir de un contexto inicial que proveerémos. Luego, harémos fine tuning a este modelo con un dataset de podcast en inglés del investigador de IA Lex Fridman y observar como cambia la generación de texto en función del dataset que utilicemos.\n",
    "\n",
    "#### Referencias\n",
    "- Dataset: https://huggingface.co/datasets/RamAnanth1/lex-fridman-podcasts\n",
    "- https://huggingface.co/EleutherAI/gpt-neo-2.7B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "3"
   },
   "source": [
    "### 1. Importación de librerias y carga de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "4"
   },
   "source": [
    "Inicio importando las librerías necesarias para el procesamiento de lenguaje natural, la manipulación de datos y la construcción del modelo. Esto incluye NumPy y pandas para el manejo y análisis de datos; Hugging Face Datasets y Transformers para la carga de corpus y la tokenización; y PyTorch junto con PyTorch Lightning para definir, entrenar y evaluar el modelo de manera estructurada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232f9b07-b6e9-4e9b-96fa-697d4f04b78a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "232f9b07-b6e9-4e9b-96fa-697d4f04b78a",
    "outputId": "7ee2e05e-4232-470e-e7b9-b477146e3dcd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jepil\\AppData\\Local\\Temp\\ipykernel_16548\\2396000874.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "installed_packages = [package.key for package in pkg_resources.working_set]\n",
    "IN_COLAB = 'google-colab' in installed_packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5",
    "outputId": "49bc103e-5a48-44d5-a92b-2b1067dcfdc2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n",
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n",
      "\"test\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n",
      "\"test\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n",
      "\"test\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n",
      "\"test\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n",
      "\"test\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!wget -O requirements.txt https://raw.githubusercontent.com/jepilogo97/nlp/main/nlp-with-gpt/requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6",
   "metadata": {
    "id": "6"
   },
   "outputs": [],
   "source": [
    "# Procesamiento de lenguaje natural y utilidades\n",
    "import numpy as np  # Cálculo numérico y manejo de arreglos multidimensionales\n",
    "import pandas as pd  # Manipulación y análisis de datos en estructuras tipo DataFrame\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)     # Todas las filas\n",
    "pd.set_option(\"display.max_columns\", None)  # Todas las columnas\n",
    "pd.set_option(\"display.width\", None)        # No cortar líneas\n",
    "\n",
    "from datasets import Dataset, load_dataset, concatenate_datasets  # Carga y combinación de datasets de Hugging Face\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from collections import Counter  # Conteo de frecuencias de elementos (tokens, palabras, etc.)\n",
    "import os  # Manejo de rutas, archivos y operaciones del sistema de archivos\n",
    "import math  # Funciones matemáticas avanzadas (logaritmos, potencias, trigonometría, etc.)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Deep Learning con PyTorch\n",
    "import torch  # Librería principal de tensores y operaciones en GPU/CPU\n",
    "import torch.nn as nn  # Definición de capas y módulos de redes neuronales\n",
    "import torch.nn.functional as F  # Funciones de activación y operaciones matemáticas de redes\n",
    "from torch.utils.data import random_split, DataLoader, Subset  # Utilidades para crear y dividir datasets, cargar lotes y trabajar con subconjuntos\n",
    "from torchinfo import summary\n",
    "\n",
    "# Entrenamiento estructurado con PyTorch Lightning\n",
    "from pytorch_lightning import LightningModule, Trainer  # Clase base y manejador de entrenamiento de modelos\n",
    "from pytorch_lightning.loggers import TensorBoardLogger  # Registro de métricas e historial en TensorBoard\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint  # Detener entrenamiento si no mejora la métrica\n",
    "from torchmetrics import Accuracy  # Métrica de precisión para clasificación supervisada\n",
    "\n",
    "# Tipado para mayor legibilidad y validación de funciones\n",
    "from typing import Optional, Tuple # Definición de tipos de datos para funciones y estructuras\n",
    "\n",
    "from tqdm.auto import tqdm  # Barra de progreso adaptable para bucles\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM  # Tokenizador automático de modelos preentrenados de Hugging Face\n",
    "from transformers.models.gpt2.tokenization_gpt2 import bytes_to_unicode  # Conversión de bytes a caracteres Unicode (usado en tokenización tipo GPT-2)\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "\n",
    "# Métricas de evaluación con Scikit-learn\n",
    "from sklearn.model_selection import train_test_split  # División de datos en conjuntos de entrenamiento y prueba\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report  # Métricas de evaluación de modelos de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "7"
   },
   "source": [
    "### 2. Generative pre-training Transformer - GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "8"
   },
   "source": [
    "Los modelos tipo GPT, introducidos por Radfor, et.al., de OpenAI, al igual que los modelos BERT, hacen uso extensivo de la arquitectura de transformers como hemos estado viendo. Las diferencias claves se podrían resumir en:\n",
    "\n",
    "1. GPT utiliza bloques de **Transformer Decoder** encadenados, mientras que el modelo BERT utiliza bloques de *Transformer Encoder*\n",
    "2. GPT se centra en la generación de texto basado en un contexto, la tarea principal es la predicción del siguiente token en la secuencia, mientras que BERT se centra en el completado de partes de una secuencia, en función de un contexto anterior y posterior a la secuencia de entrada. Entonces BERT se centra en la construicción de representación de lenguage, mientras que GPT se centra en la generación de texto en función de un contexto.\n",
    "\n",
    "Sin embargo, ambos se basan en la misma premisa de pre-entrenar el modelo en tareas no-supervisadas o semi-supervisadas para que el modelo aprenda las representaciones semánticas del lenguage y luego al modelo se le pueda hacer fine tuning a tareas posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351,
     "referenced_widgets": [
      "ea21f66b04904e1da5509548d005326d",
      "cc31cd360dea4b7f9f1527120b240dda",
      "e83dae96221e4df7910cb9c9587f1285",
      "f9a61115f163409f99ba17387f550180",
      "32171b576b78400fb3e1d3795ac4ee7e",
      "09b30e3eaa8f490c93cc5c82d9e3bea0",
      "57b7510653b140ac82befbcaf595a90c",
      "1455328eba4d423d90ff9f8382fc07c1",
      "fe053251c70e41ad82cf6188450e3cb1",
      "522e6abb62a7405597675fb8a2fe85d6",
      "e6baf2e8f4d2484e925073d2d0b9963e",
      "1ae2b20268b0482fb63cfcd5d9614bb9",
      "e5f487de564441fdbb03f41697e1f48b",
      "b5469598024b4f018731c1eb19dc9f82",
      "f31a2948554745a791f207016687e1e8",
      "f261ed77b42b44a9a2b8ff70ebb9f76d",
      "7350223d702f4c81b641ec89413fc386",
      "c31db8adbd684018b3f8b53432ae3d3c",
      "c0e2a4a2cf72421b8dd8279453cd726f",
      "07af5dd4922f4df798514a41389a91a1",
      "51e1fa69e6134de7994629407a4a34ce",
      "3b71c0b5d55f4a4598b4d2e354944afb",
      "2d11144b0451428899933590a1405d0e",
      "c41af65471b84952adb47b60992a53ec",
      "d03369b1a9d04fee915022448dfd513e",
      "83308e359c0d4cff909af76d3ebaa4f7",
      "ab22cc2af7c84d2dba881a9ca953fab7",
      "487e54962be045e985e9acc3ce2d0671",
      "6f812eddd24b4018a412551b2f349da8",
      "9f4b7168a78b407d9c85cbeb6c38826c",
      "9eb5451ca3894648b24540cf15877bd3",
      "0568b53102ad4c0a904b7ac7ecafff89",
      "025cc330230b48758656b4c482815b2d",
      "2d274ba17245445990222801a0eae57f",
      "6c767369b09a49a0bd905a4e000fc75d",
      "d7bae0cdb323422e826093597514d6b0",
      "4c922e7cf71f4e75adbdde73c521af2c",
      "baa7e61aa98e4ead86f3e83ac5880fa5",
      "a42af96621cc4c1891f7108870ec3c73",
      "9e483d52ff924ef7b7960d0389f7ab75",
      "43c2a1a404bf437699f65e3bb537c2c2",
      "cb4381d3be22412e85e9cec703bda118",
      "364d2acbe353410d85cd72c8f9306a68",
      "cc0065dbc5bd4da398ec132bb3d235a5",
      "d5076356e17d4d2f8feeeb0d76b6a059",
      "adf364ba955f46e083845fb0d84ac195",
      "1c3151889d39433bb5c16eedd55599ea",
      "7bed3bb564d449478f16c899400c649b",
      "e239729298634ed195788778ed4c5612",
      "b30200d050d944e0b1a03c5606b10b24",
      "ece93993a64a4e58b8b175e8da0337a9",
      "9e30a3df40a841fe8ac9f9dbbc4cf7a9",
      "fff936f3e2bf47da8fc189bb0c05a086",
      "8de3700fdb504366b00a5a68e8576140",
      "c449369093464fbb8a03e3cdabbe7733"
     ]
    },
    "id": "9",
    "outputId": "2106256a-a28c-4e89-f05e-4386996ddc09",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 2560)\n",
       "    (wpe): Embedding(2048, 2560)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"EleutherAI/gpt-neo-2.7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f92fe6ed-e49e-475b-b883-228d3745744e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'transformer',\n",
       " 'transformer.wte',\n",
       " 'transformer.wpe',\n",
       " 'transformer.drop',\n",
       " 'transformer.h',\n",
       " 'transformer.h.0',\n",
       " 'transformer.h.0.ln_1',\n",
       " 'transformer.h.0.attn',\n",
       " 'transformer.h.0.attn.attention',\n",
       " 'transformer.h.0.attn.attention.attn_dropout',\n",
       " 'transformer.h.0.attn.attention.resid_dropout',\n",
       " 'transformer.h.0.attn.attention.k_proj',\n",
       " 'transformer.h.0.attn.attention.v_proj',\n",
       " 'transformer.h.0.attn.attention.q_proj',\n",
       " 'transformer.h.0.attn.attention.out_proj',\n",
       " 'transformer.h.0.ln_2',\n",
       " 'transformer.h.0.mlp',\n",
       " 'transformer.h.0.mlp.c_fc',\n",
       " 'transformer.h.0.mlp.c_proj',\n",
       " 'transformer.h.0.mlp.act',\n",
       " 'transformer.h.0.mlp.dropout',\n",
       " 'transformer.h.1',\n",
       " 'transformer.h.1.ln_1',\n",
       " 'transformer.h.1.attn',\n",
       " 'transformer.h.1.attn.attention',\n",
       " 'transformer.h.1.attn.attention.attn_dropout',\n",
       " 'transformer.h.1.attn.attention.resid_dropout',\n",
       " 'transformer.h.1.attn.attention.k_proj',\n",
       " 'transformer.h.1.attn.attention.v_proj',\n",
       " 'transformer.h.1.attn.attention.q_proj',\n",
       " 'transformer.h.1.attn.attention.out_proj',\n",
       " 'transformer.h.1.ln_2',\n",
       " 'transformer.h.1.mlp',\n",
       " 'transformer.h.1.mlp.c_fc',\n",
       " 'transformer.h.1.mlp.c_proj',\n",
       " 'transformer.h.1.mlp.act',\n",
       " 'transformer.h.1.mlp.dropout',\n",
       " 'transformer.h.2',\n",
       " 'transformer.h.2.ln_1',\n",
       " 'transformer.h.2.attn',\n",
       " 'transformer.h.2.attn.attention',\n",
       " 'transformer.h.2.attn.attention.attn_dropout',\n",
       " 'transformer.h.2.attn.attention.resid_dropout',\n",
       " 'transformer.h.2.attn.attention.k_proj',\n",
       " 'transformer.h.2.attn.attention.v_proj',\n",
       " 'transformer.h.2.attn.attention.q_proj',\n",
       " 'transformer.h.2.attn.attention.out_proj',\n",
       " 'transformer.h.2.ln_2',\n",
       " 'transformer.h.2.mlp',\n",
       " 'transformer.h.2.mlp.c_fc',\n",
       " 'transformer.h.2.mlp.c_proj',\n",
       " 'transformer.h.2.mlp.act',\n",
       " 'transformer.h.2.mlp.dropout',\n",
       " 'transformer.h.3',\n",
       " 'transformer.h.3.ln_1',\n",
       " 'transformer.h.3.attn',\n",
       " 'transformer.h.3.attn.attention',\n",
       " 'transformer.h.3.attn.attention.attn_dropout',\n",
       " 'transformer.h.3.attn.attention.resid_dropout',\n",
       " 'transformer.h.3.attn.attention.k_proj',\n",
       " 'transformer.h.3.attn.attention.v_proj',\n",
       " 'transformer.h.3.attn.attention.q_proj',\n",
       " 'transformer.h.3.attn.attention.out_proj',\n",
       " 'transformer.h.3.ln_2',\n",
       " 'transformer.h.3.mlp',\n",
       " 'transformer.h.3.mlp.c_fc',\n",
       " 'transformer.h.3.mlp.c_proj',\n",
       " 'transformer.h.3.mlp.act',\n",
       " 'transformer.h.3.mlp.dropout',\n",
       " 'transformer.h.4',\n",
       " 'transformer.h.4.ln_1',\n",
       " 'transformer.h.4.attn',\n",
       " 'transformer.h.4.attn.attention',\n",
       " 'transformer.h.4.attn.attention.attn_dropout',\n",
       " 'transformer.h.4.attn.attention.resid_dropout',\n",
       " 'transformer.h.4.attn.attention.k_proj',\n",
       " 'transformer.h.4.attn.attention.v_proj',\n",
       " 'transformer.h.4.attn.attention.q_proj',\n",
       " 'transformer.h.4.attn.attention.out_proj',\n",
       " 'transformer.h.4.ln_2',\n",
       " 'transformer.h.4.mlp',\n",
       " 'transformer.h.4.mlp.c_fc',\n",
       " 'transformer.h.4.mlp.c_proj',\n",
       " 'transformer.h.4.mlp.act',\n",
       " 'transformer.h.4.mlp.dropout',\n",
       " 'transformer.h.5',\n",
       " 'transformer.h.5.ln_1',\n",
       " 'transformer.h.5.attn',\n",
       " 'transformer.h.5.attn.attention',\n",
       " 'transformer.h.5.attn.attention.attn_dropout',\n",
       " 'transformer.h.5.attn.attention.resid_dropout',\n",
       " 'transformer.h.5.attn.attention.k_proj',\n",
       " 'transformer.h.5.attn.attention.v_proj',\n",
       " 'transformer.h.5.attn.attention.q_proj',\n",
       " 'transformer.h.5.attn.attention.out_proj',\n",
       " 'transformer.h.5.ln_2',\n",
       " 'transformer.h.5.mlp',\n",
       " 'transformer.h.5.mlp.c_fc',\n",
       " 'transformer.h.5.mlp.c_proj',\n",
       " 'transformer.h.5.mlp.act',\n",
       " 'transformer.h.5.mlp.dropout',\n",
       " 'transformer.h.6',\n",
       " 'transformer.h.6.ln_1',\n",
       " 'transformer.h.6.attn',\n",
       " 'transformer.h.6.attn.attention',\n",
       " 'transformer.h.6.attn.attention.attn_dropout',\n",
       " 'transformer.h.6.attn.attention.resid_dropout',\n",
       " 'transformer.h.6.attn.attention.k_proj',\n",
       " 'transformer.h.6.attn.attention.v_proj',\n",
       " 'transformer.h.6.attn.attention.q_proj',\n",
       " 'transformer.h.6.attn.attention.out_proj',\n",
       " 'transformer.h.6.ln_2',\n",
       " 'transformer.h.6.mlp',\n",
       " 'transformer.h.6.mlp.c_fc',\n",
       " 'transformer.h.6.mlp.c_proj',\n",
       " 'transformer.h.6.mlp.act',\n",
       " 'transformer.h.6.mlp.dropout',\n",
       " 'transformer.h.7',\n",
       " 'transformer.h.7.ln_1',\n",
       " 'transformer.h.7.attn',\n",
       " 'transformer.h.7.attn.attention',\n",
       " 'transformer.h.7.attn.attention.attn_dropout',\n",
       " 'transformer.h.7.attn.attention.resid_dropout',\n",
       " 'transformer.h.7.attn.attention.k_proj',\n",
       " 'transformer.h.7.attn.attention.v_proj',\n",
       " 'transformer.h.7.attn.attention.q_proj',\n",
       " 'transformer.h.7.attn.attention.out_proj',\n",
       " 'transformer.h.7.ln_2',\n",
       " 'transformer.h.7.mlp',\n",
       " 'transformer.h.7.mlp.c_fc',\n",
       " 'transformer.h.7.mlp.c_proj',\n",
       " 'transformer.h.7.mlp.act',\n",
       " 'transformer.h.7.mlp.dropout',\n",
       " 'transformer.h.8',\n",
       " 'transformer.h.8.ln_1',\n",
       " 'transformer.h.8.attn',\n",
       " 'transformer.h.8.attn.attention',\n",
       " 'transformer.h.8.attn.attention.attn_dropout',\n",
       " 'transformer.h.8.attn.attention.resid_dropout',\n",
       " 'transformer.h.8.attn.attention.k_proj',\n",
       " 'transformer.h.8.attn.attention.v_proj',\n",
       " 'transformer.h.8.attn.attention.q_proj',\n",
       " 'transformer.h.8.attn.attention.out_proj',\n",
       " 'transformer.h.8.ln_2',\n",
       " 'transformer.h.8.mlp',\n",
       " 'transformer.h.8.mlp.c_fc',\n",
       " 'transformer.h.8.mlp.c_proj',\n",
       " 'transformer.h.8.mlp.act',\n",
       " 'transformer.h.8.mlp.dropout',\n",
       " 'transformer.h.9',\n",
       " 'transformer.h.9.ln_1',\n",
       " 'transformer.h.9.attn',\n",
       " 'transformer.h.9.attn.attention',\n",
       " 'transformer.h.9.attn.attention.attn_dropout',\n",
       " 'transformer.h.9.attn.attention.resid_dropout',\n",
       " 'transformer.h.9.attn.attention.k_proj',\n",
       " 'transformer.h.9.attn.attention.v_proj',\n",
       " 'transformer.h.9.attn.attention.q_proj',\n",
       " 'transformer.h.9.attn.attention.out_proj',\n",
       " 'transformer.h.9.ln_2',\n",
       " 'transformer.h.9.mlp',\n",
       " 'transformer.h.9.mlp.c_fc',\n",
       " 'transformer.h.9.mlp.c_proj',\n",
       " 'transformer.h.9.mlp.act',\n",
       " 'transformer.h.9.mlp.dropout',\n",
       " 'transformer.h.10',\n",
       " 'transformer.h.10.ln_1',\n",
       " 'transformer.h.10.attn',\n",
       " 'transformer.h.10.attn.attention',\n",
       " 'transformer.h.10.attn.attention.attn_dropout',\n",
       " 'transformer.h.10.attn.attention.resid_dropout',\n",
       " 'transformer.h.10.attn.attention.k_proj',\n",
       " 'transformer.h.10.attn.attention.v_proj',\n",
       " 'transformer.h.10.attn.attention.q_proj',\n",
       " 'transformer.h.10.attn.attention.out_proj',\n",
       " 'transformer.h.10.ln_2',\n",
       " 'transformer.h.10.mlp',\n",
       " 'transformer.h.10.mlp.c_fc',\n",
       " 'transformer.h.10.mlp.c_proj',\n",
       " 'transformer.h.10.mlp.act',\n",
       " 'transformer.h.10.mlp.dropout',\n",
       " 'transformer.h.11',\n",
       " 'transformer.h.11.ln_1',\n",
       " 'transformer.h.11.attn',\n",
       " 'transformer.h.11.attn.attention',\n",
       " 'transformer.h.11.attn.attention.attn_dropout',\n",
       " 'transformer.h.11.attn.attention.resid_dropout',\n",
       " 'transformer.h.11.attn.attention.k_proj',\n",
       " 'transformer.h.11.attn.attention.v_proj',\n",
       " 'transformer.h.11.attn.attention.q_proj',\n",
       " 'transformer.h.11.attn.attention.out_proj',\n",
       " 'transformer.h.11.ln_2',\n",
       " 'transformer.h.11.mlp',\n",
       " 'transformer.h.11.mlp.c_fc',\n",
       " 'transformer.h.11.mlp.c_proj',\n",
       " 'transformer.h.11.mlp.act',\n",
       " 'transformer.h.11.mlp.dropout',\n",
       " 'transformer.h.12',\n",
       " 'transformer.h.12.ln_1',\n",
       " 'transformer.h.12.attn',\n",
       " 'transformer.h.12.attn.attention',\n",
       " 'transformer.h.12.attn.attention.attn_dropout',\n",
       " 'transformer.h.12.attn.attention.resid_dropout',\n",
       " 'transformer.h.12.attn.attention.k_proj',\n",
       " 'transformer.h.12.attn.attention.v_proj',\n",
       " 'transformer.h.12.attn.attention.q_proj',\n",
       " 'transformer.h.12.attn.attention.out_proj',\n",
       " 'transformer.h.12.ln_2',\n",
       " 'transformer.h.12.mlp',\n",
       " 'transformer.h.12.mlp.c_fc',\n",
       " 'transformer.h.12.mlp.c_proj',\n",
       " 'transformer.h.12.mlp.act',\n",
       " 'transformer.h.12.mlp.dropout',\n",
       " 'transformer.h.13',\n",
       " 'transformer.h.13.ln_1',\n",
       " 'transformer.h.13.attn',\n",
       " 'transformer.h.13.attn.attention',\n",
       " 'transformer.h.13.attn.attention.attn_dropout',\n",
       " 'transformer.h.13.attn.attention.resid_dropout',\n",
       " 'transformer.h.13.attn.attention.k_proj',\n",
       " 'transformer.h.13.attn.attention.v_proj',\n",
       " 'transformer.h.13.attn.attention.q_proj',\n",
       " 'transformer.h.13.attn.attention.out_proj',\n",
       " 'transformer.h.13.ln_2',\n",
       " 'transformer.h.13.mlp',\n",
       " 'transformer.h.13.mlp.c_fc',\n",
       " 'transformer.h.13.mlp.c_proj',\n",
       " 'transformer.h.13.mlp.act',\n",
       " 'transformer.h.13.mlp.dropout',\n",
       " 'transformer.h.14',\n",
       " 'transformer.h.14.ln_1',\n",
       " 'transformer.h.14.attn',\n",
       " 'transformer.h.14.attn.attention',\n",
       " 'transformer.h.14.attn.attention.attn_dropout',\n",
       " 'transformer.h.14.attn.attention.resid_dropout',\n",
       " 'transformer.h.14.attn.attention.k_proj',\n",
       " 'transformer.h.14.attn.attention.v_proj',\n",
       " 'transformer.h.14.attn.attention.q_proj',\n",
       " 'transformer.h.14.attn.attention.out_proj',\n",
       " 'transformer.h.14.ln_2',\n",
       " 'transformer.h.14.mlp',\n",
       " 'transformer.h.14.mlp.c_fc',\n",
       " 'transformer.h.14.mlp.c_proj',\n",
       " 'transformer.h.14.mlp.act',\n",
       " 'transformer.h.14.mlp.dropout',\n",
       " 'transformer.h.15',\n",
       " 'transformer.h.15.ln_1',\n",
       " 'transformer.h.15.attn',\n",
       " 'transformer.h.15.attn.attention',\n",
       " 'transformer.h.15.attn.attention.attn_dropout',\n",
       " 'transformer.h.15.attn.attention.resid_dropout',\n",
       " 'transformer.h.15.attn.attention.k_proj',\n",
       " 'transformer.h.15.attn.attention.v_proj',\n",
       " 'transformer.h.15.attn.attention.q_proj',\n",
       " 'transformer.h.15.attn.attention.out_proj',\n",
       " 'transformer.h.15.ln_2',\n",
       " 'transformer.h.15.mlp',\n",
       " 'transformer.h.15.mlp.c_fc',\n",
       " 'transformer.h.15.mlp.c_proj',\n",
       " 'transformer.h.15.mlp.act',\n",
       " 'transformer.h.15.mlp.dropout',\n",
       " 'transformer.h.16',\n",
       " 'transformer.h.16.ln_1',\n",
       " 'transformer.h.16.attn',\n",
       " 'transformer.h.16.attn.attention',\n",
       " 'transformer.h.16.attn.attention.attn_dropout',\n",
       " 'transformer.h.16.attn.attention.resid_dropout',\n",
       " 'transformer.h.16.attn.attention.k_proj',\n",
       " 'transformer.h.16.attn.attention.v_proj',\n",
       " 'transformer.h.16.attn.attention.q_proj',\n",
       " 'transformer.h.16.attn.attention.out_proj',\n",
       " 'transformer.h.16.ln_2',\n",
       " 'transformer.h.16.mlp',\n",
       " 'transformer.h.16.mlp.c_fc',\n",
       " 'transformer.h.16.mlp.c_proj',\n",
       " 'transformer.h.16.mlp.act',\n",
       " 'transformer.h.16.mlp.dropout',\n",
       " 'transformer.h.17',\n",
       " 'transformer.h.17.ln_1',\n",
       " 'transformer.h.17.attn',\n",
       " 'transformer.h.17.attn.attention',\n",
       " 'transformer.h.17.attn.attention.attn_dropout',\n",
       " 'transformer.h.17.attn.attention.resid_dropout',\n",
       " 'transformer.h.17.attn.attention.k_proj',\n",
       " 'transformer.h.17.attn.attention.v_proj',\n",
       " 'transformer.h.17.attn.attention.q_proj',\n",
       " 'transformer.h.17.attn.attention.out_proj',\n",
       " 'transformer.h.17.ln_2',\n",
       " 'transformer.h.17.mlp',\n",
       " 'transformer.h.17.mlp.c_fc',\n",
       " 'transformer.h.17.mlp.c_proj',\n",
       " 'transformer.h.17.mlp.act',\n",
       " 'transformer.h.17.mlp.dropout',\n",
       " 'transformer.h.18',\n",
       " 'transformer.h.18.ln_1',\n",
       " 'transformer.h.18.attn',\n",
       " 'transformer.h.18.attn.attention',\n",
       " 'transformer.h.18.attn.attention.attn_dropout',\n",
       " 'transformer.h.18.attn.attention.resid_dropout',\n",
       " 'transformer.h.18.attn.attention.k_proj',\n",
       " 'transformer.h.18.attn.attention.v_proj',\n",
       " 'transformer.h.18.attn.attention.q_proj',\n",
       " 'transformer.h.18.attn.attention.out_proj',\n",
       " 'transformer.h.18.ln_2',\n",
       " 'transformer.h.18.mlp',\n",
       " 'transformer.h.18.mlp.c_fc',\n",
       " 'transformer.h.18.mlp.c_proj',\n",
       " 'transformer.h.18.mlp.act',\n",
       " 'transformer.h.18.mlp.dropout',\n",
       " 'transformer.h.19',\n",
       " 'transformer.h.19.ln_1',\n",
       " 'transformer.h.19.attn',\n",
       " 'transformer.h.19.attn.attention',\n",
       " 'transformer.h.19.attn.attention.attn_dropout',\n",
       " 'transformer.h.19.attn.attention.resid_dropout',\n",
       " 'transformer.h.19.attn.attention.k_proj',\n",
       " 'transformer.h.19.attn.attention.v_proj',\n",
       " 'transformer.h.19.attn.attention.q_proj',\n",
       " 'transformer.h.19.attn.attention.out_proj',\n",
       " 'transformer.h.19.ln_2',\n",
       " 'transformer.h.19.mlp',\n",
       " 'transformer.h.19.mlp.c_fc',\n",
       " 'transformer.h.19.mlp.c_proj',\n",
       " 'transformer.h.19.mlp.act',\n",
       " 'transformer.h.19.mlp.dropout',\n",
       " 'transformer.h.20',\n",
       " 'transformer.h.20.ln_1',\n",
       " 'transformer.h.20.attn',\n",
       " 'transformer.h.20.attn.attention',\n",
       " 'transformer.h.20.attn.attention.attn_dropout',\n",
       " 'transformer.h.20.attn.attention.resid_dropout',\n",
       " 'transformer.h.20.attn.attention.k_proj',\n",
       " 'transformer.h.20.attn.attention.v_proj',\n",
       " 'transformer.h.20.attn.attention.q_proj',\n",
       " 'transformer.h.20.attn.attention.out_proj',\n",
       " 'transformer.h.20.ln_2',\n",
       " 'transformer.h.20.mlp',\n",
       " 'transformer.h.20.mlp.c_fc',\n",
       " 'transformer.h.20.mlp.c_proj',\n",
       " 'transformer.h.20.mlp.act',\n",
       " 'transformer.h.20.mlp.dropout',\n",
       " 'transformer.h.21',\n",
       " 'transformer.h.21.ln_1',\n",
       " 'transformer.h.21.attn',\n",
       " 'transformer.h.21.attn.attention',\n",
       " 'transformer.h.21.attn.attention.attn_dropout',\n",
       " 'transformer.h.21.attn.attention.resid_dropout',\n",
       " 'transformer.h.21.attn.attention.k_proj',\n",
       " 'transformer.h.21.attn.attention.v_proj',\n",
       " 'transformer.h.21.attn.attention.q_proj',\n",
       " 'transformer.h.21.attn.attention.out_proj',\n",
       " 'transformer.h.21.ln_2',\n",
       " 'transformer.h.21.mlp',\n",
       " 'transformer.h.21.mlp.c_fc',\n",
       " 'transformer.h.21.mlp.c_proj',\n",
       " 'transformer.h.21.mlp.act',\n",
       " 'transformer.h.21.mlp.dropout',\n",
       " 'transformer.h.22',\n",
       " 'transformer.h.22.ln_1',\n",
       " 'transformer.h.22.attn',\n",
       " 'transformer.h.22.attn.attention',\n",
       " 'transformer.h.22.attn.attention.attn_dropout',\n",
       " 'transformer.h.22.attn.attention.resid_dropout',\n",
       " 'transformer.h.22.attn.attention.k_proj',\n",
       " 'transformer.h.22.attn.attention.v_proj',\n",
       " 'transformer.h.22.attn.attention.q_proj',\n",
       " 'transformer.h.22.attn.attention.out_proj',\n",
       " 'transformer.h.22.ln_2',\n",
       " 'transformer.h.22.mlp',\n",
       " 'transformer.h.22.mlp.c_fc',\n",
       " 'transformer.h.22.mlp.c_proj',\n",
       " 'transformer.h.22.mlp.act',\n",
       " 'transformer.h.22.mlp.dropout',\n",
       " 'transformer.h.23',\n",
       " 'transformer.h.23.ln_1',\n",
       " 'transformer.h.23.attn',\n",
       " 'transformer.h.23.attn.attention',\n",
       " 'transformer.h.23.attn.attention.attn_dropout',\n",
       " 'transformer.h.23.attn.attention.resid_dropout',\n",
       " 'transformer.h.23.attn.attention.k_proj',\n",
       " 'transformer.h.23.attn.attention.v_proj',\n",
       " 'transformer.h.23.attn.attention.q_proj',\n",
       " 'transformer.h.23.attn.attention.out_proj',\n",
       " 'transformer.h.23.ln_2',\n",
       " 'transformer.h.23.mlp',\n",
       " 'transformer.h.23.mlp.c_fc',\n",
       " 'transformer.h.23.mlp.c_proj',\n",
       " 'transformer.h.23.mlp.act',\n",
       " 'transformer.h.23.mlp.dropout',\n",
       " 'transformer.h.24',\n",
       " 'transformer.h.24.ln_1',\n",
       " 'transformer.h.24.attn',\n",
       " 'transformer.h.24.attn.attention',\n",
       " 'transformer.h.24.attn.attention.attn_dropout',\n",
       " 'transformer.h.24.attn.attention.resid_dropout',\n",
       " 'transformer.h.24.attn.attention.k_proj',\n",
       " 'transformer.h.24.attn.attention.v_proj',\n",
       " 'transformer.h.24.attn.attention.q_proj',\n",
       " 'transformer.h.24.attn.attention.out_proj',\n",
       " 'transformer.h.24.ln_2',\n",
       " 'transformer.h.24.mlp',\n",
       " 'transformer.h.24.mlp.c_fc',\n",
       " 'transformer.h.24.mlp.c_proj',\n",
       " 'transformer.h.24.mlp.act',\n",
       " 'transformer.h.24.mlp.dropout',\n",
       " 'transformer.h.25',\n",
       " 'transformer.h.25.ln_1',\n",
       " 'transformer.h.25.attn',\n",
       " 'transformer.h.25.attn.attention',\n",
       " 'transformer.h.25.attn.attention.attn_dropout',\n",
       " 'transformer.h.25.attn.attention.resid_dropout',\n",
       " 'transformer.h.25.attn.attention.k_proj',\n",
       " 'transformer.h.25.attn.attention.v_proj',\n",
       " 'transformer.h.25.attn.attention.q_proj',\n",
       " 'transformer.h.25.attn.attention.out_proj',\n",
       " 'transformer.h.25.ln_2',\n",
       " 'transformer.h.25.mlp',\n",
       " 'transformer.h.25.mlp.c_fc',\n",
       " 'transformer.h.25.mlp.c_proj',\n",
       " 'transformer.h.25.mlp.act',\n",
       " 'transformer.h.25.mlp.dropout',\n",
       " 'transformer.h.26',\n",
       " 'transformer.h.26.ln_1',\n",
       " 'transformer.h.26.attn',\n",
       " 'transformer.h.26.attn.attention',\n",
       " 'transformer.h.26.attn.attention.attn_dropout',\n",
       " 'transformer.h.26.attn.attention.resid_dropout',\n",
       " 'transformer.h.26.attn.attention.k_proj',\n",
       " 'transformer.h.26.attn.attention.v_proj',\n",
       " 'transformer.h.26.attn.attention.q_proj',\n",
       " 'transformer.h.26.attn.attention.out_proj',\n",
       " 'transformer.h.26.ln_2',\n",
       " 'transformer.h.26.mlp',\n",
       " 'transformer.h.26.mlp.c_fc',\n",
       " 'transformer.h.26.mlp.c_proj',\n",
       " 'transformer.h.26.mlp.act',\n",
       " 'transformer.h.26.mlp.dropout',\n",
       " 'transformer.h.27',\n",
       " 'transformer.h.27.ln_1',\n",
       " 'transformer.h.27.attn',\n",
       " 'transformer.h.27.attn.attention',\n",
       " 'transformer.h.27.attn.attention.attn_dropout',\n",
       " 'transformer.h.27.attn.attention.resid_dropout',\n",
       " 'transformer.h.27.attn.attention.k_proj',\n",
       " 'transformer.h.27.attn.attention.v_proj',\n",
       " 'transformer.h.27.attn.attention.q_proj',\n",
       " 'transformer.h.27.attn.attention.out_proj',\n",
       " 'transformer.h.27.ln_2',\n",
       " 'transformer.h.27.mlp',\n",
       " 'transformer.h.27.mlp.c_fc',\n",
       " 'transformer.h.27.mlp.c_proj',\n",
       " 'transformer.h.27.mlp.act',\n",
       " 'transformer.h.27.mlp.dropout',\n",
       " 'transformer.h.28',\n",
       " 'transformer.h.28.ln_1',\n",
       " 'transformer.h.28.attn',\n",
       " 'transformer.h.28.attn.attention',\n",
       " 'transformer.h.28.attn.attention.attn_dropout',\n",
       " 'transformer.h.28.attn.attention.resid_dropout',\n",
       " 'transformer.h.28.attn.attention.k_proj',\n",
       " 'transformer.h.28.attn.attention.v_proj',\n",
       " 'transformer.h.28.attn.attention.q_proj',\n",
       " 'transformer.h.28.attn.attention.out_proj',\n",
       " 'transformer.h.28.ln_2',\n",
       " 'transformer.h.28.mlp',\n",
       " 'transformer.h.28.mlp.c_fc',\n",
       " 'transformer.h.28.mlp.c_proj',\n",
       " 'transformer.h.28.mlp.act',\n",
       " 'transformer.h.28.mlp.dropout',\n",
       " 'transformer.h.29',\n",
       " 'transformer.h.29.ln_1',\n",
       " 'transformer.h.29.attn',\n",
       " 'transformer.h.29.attn.attention',\n",
       " 'transformer.h.29.attn.attention.attn_dropout',\n",
       " 'transformer.h.29.attn.attention.resid_dropout',\n",
       " 'transformer.h.29.attn.attention.k_proj',\n",
       " 'transformer.h.29.attn.attention.v_proj',\n",
       " 'transformer.h.29.attn.attention.q_proj',\n",
       " 'transformer.h.29.attn.attention.out_proj',\n",
       " 'transformer.h.29.ln_2',\n",
       " 'transformer.h.29.mlp',\n",
       " 'transformer.h.29.mlp.c_fc',\n",
       " 'transformer.h.29.mlp.c_proj',\n",
       " 'transformer.h.29.mlp.act',\n",
       " 'transformer.h.29.mlp.dropout',\n",
       " 'transformer.h.30',\n",
       " 'transformer.h.30.ln_1',\n",
       " 'transformer.h.30.attn',\n",
       " 'transformer.h.30.attn.attention',\n",
       " 'transformer.h.30.attn.attention.attn_dropout',\n",
       " 'transformer.h.30.attn.attention.resid_dropout',\n",
       " 'transformer.h.30.attn.attention.k_proj',\n",
       " 'transformer.h.30.attn.attention.v_proj',\n",
       " 'transformer.h.30.attn.attention.q_proj',\n",
       " 'transformer.h.30.attn.attention.out_proj',\n",
       " 'transformer.h.30.ln_2',\n",
       " 'transformer.h.30.mlp',\n",
       " 'transformer.h.30.mlp.c_fc',\n",
       " 'transformer.h.30.mlp.c_proj',\n",
       " 'transformer.h.30.mlp.act',\n",
       " 'transformer.h.30.mlp.dropout',\n",
       " 'transformer.h.31',\n",
       " 'transformer.h.31.ln_1',\n",
       " 'transformer.h.31.attn',\n",
       " 'transformer.h.31.attn.attention',\n",
       " 'transformer.h.31.attn.attention.attn_dropout',\n",
       " 'transformer.h.31.attn.attention.resid_dropout',\n",
       " 'transformer.h.31.attn.attention.k_proj',\n",
       " 'transformer.h.31.attn.attention.v_proj',\n",
       " 'transformer.h.31.attn.attention.q_proj',\n",
       " 'transformer.h.31.attn.attention.out_proj',\n",
       " 'transformer.h.31.ln_2',\n",
       " 'transformer.h.31.mlp',\n",
       " 'transformer.h.31.mlp.c_fc',\n",
       " 'transformer.h.31.mlp.c_proj',\n",
       " 'transformer.h.31.mlp.act',\n",
       " 'transformer.h.31.mlp.dropout',\n",
       " 'transformer.ln_f',\n",
       " 'lm_head']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = [m for m, _ in model.named_modules()]\n",
    "modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a8c59-a7cb-458e-be52-19116d37b264",
   "metadata": {},
   "source": [
    "Observermos un ejemplo de generación simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f6d06a4-d24b-440d-a35c-8d7ab4ce6477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la entrada: torch.Size([1, 14])\n",
      "Dimensiones de la salida: torch.Size([1, 14, 50257])\n",
      "Dimensiones del último token de la secuencia: torch.Size([50257])\n",
      "Dimensiones de la probabilidad de los tokens: torch.Size([50257])\n",
      "{' we': '26.56%', ' students': '15.52%', ' I': '7.04%', ' the': '5.74%', ' a': '2.97%', ' you': '2.32%', ' Professor': '1.70%', ' our': '1.43%', ' this': '1.11%', ' researchers': '1.07%'}\n"
     ]
    }
   ],
   "source": [
    "text = \"As part of MIT course 6S099, Artificial General Intelligence,\"\n",
    "best = 10\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens = tokenizer(text, return_tensors='pt')['input_ids'].to(device)\n",
    "    print(\"Dimensiones de la entrada:\", tokens.shape)\n",
    "    output = model(input_ids=tokens)\n",
    "    print(\"Dimensiones de la salida:\", output.logits.shape)\n",
    "    output = output.logits[0, -1, :]\n",
    "    print(\"Dimensiones del último token de la secuencia:\", output.shape)\n",
    "    probs = torch.softmax(output, dim=-1)\n",
    "    print(\"Dimensiones de la probabilidad de los tokens:\", probs.shape)\n",
    "    sorted_probs = torch.argsort(probs, dim=-1, descending=True)\n",
    "    print({tokenizer.decode(token): f\"{prob.cpu().numpy() * 100:.2f}%\" for token, prob in zip(sorted_probs[:best], probs[sorted_probs[:best]])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "20"
   },
   "source": [
    "### 2. Implementando una función de generación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "id": "21"
   },
   "source": [
    "Ahora, la idea es que este modelo nos sirva para generar texto de forma recurrente e incremental. En la última capa de los modelos tipo GPT encontrarémos un tensor con forma $(b, s, v)$, donde:\n",
    "\n",
    "- $b$: Es el tamaño del bache, o la cantidad de secuencias a procesar.\n",
    "- $s$: Es la longitud de la secuencia de entrada.\n",
    "- $v$: Es el tamaño del vocabulario del modelo, cuantos tokens soporta.\n",
    "\n",
    "Pero este es el tensor de salida, por qué tiene la forma de la secuencia de entrada?, porque cada posición en la salida corresponde a la la predicción del siguiente token de esa posición en la secuencia de entrada. En otras palabras, lo que obtenemos como predicción, es una secuencia de igual tamaño a la de entrada, movida un token hacia adelante, lo que efectivamente nos predice un solo token a la vez y por ende, el token que nos insteresa, es el último.\n",
    "\n",
    "Lo que obtenemos en este tensor es además los logits de TODO el vocabulario del modelo, con los cuales podemos calcular las probabilidades de que cada uno sea el que continue en la secuencia. Hay varias formas de decodificar el siguiente token, la más fácil de implementar sería una decodificación codiciosa (greedy) del siguiente token, que consiste simplemente en seleccionar el token con la probabilidad más alta. Este es un enfoque simple y efectivo para algunos casos, pero al mismo tiempo sufre de poca variabilidad e incluso puede caer en generación repetitiva.\n",
    "\n",
    "Otra opción es el muestreo, ya que justamente podemos obtener probabilidades del siguiente token, lo más lógico sería muestrear con esas opciones de probabilidad, de este modo podemos obtener mayor diversidad a la hora de generar el texto, al costo eso si de que haya mayor aleatoridad ya que se le daría la oportunidad a incluso tokens con baja probabilidad, de ser seleccionados.\n",
    "\n",
    "Otra opción podría ser un balanceo entre una decodificación greedy y una por muestreo, en función de otro hiperparámetro que podemos definir. Esta sería una técnica muy común en el contexto de Reinforcement Learning llamade e-greedy. Se hace la aclaración de que en este ejemplo no harémos nada de RL, solamente se hace mención de esta técnica para balancear entre explotación y exploración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e473a39-4f5c-4ee4-80b5-c84a5eaa6094",
   "metadata": {
    "id": "075182ed-20f6-4cbf-b0da-66b29e9b40d7"
   },
   "outputs": [],
   "source": [
    "def generate(\n",
    "        model: nn.Module, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        start: str, \n",
    "        max_length: int = 1000, \n",
    "        eps: float = 0.5, \n",
    "        top_n: int = 5,\n",
    "        return_iterations: bool = False,\n",
    "        device: str = \"cpu\") -> Tuple[str, Optional[pd.DataFrame]]:\n",
    "\n",
    "    output = [start]\n",
    "    iterations = []\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer(output[-1], return_tensors='pt')['input_ids'].to(device)\n",
    "        for _ in range(max_length):\n",
    "            # Tomamos los logits producidos por la última capa del modelo\n",
    "            # Estos corresponden al siguiente token por cada posición de la cadena\n",
    "            logits = model(input_ids=input_ids).logits\n",
    "            # Por lo tanto, el que nos interesa es el último, que correspondería a la\n",
    "            # predicción del siguiente token después del final de la cadena original\n",
    "            # A este aplicamos un softmax para obtener las probabilidades por cada\n",
    "            # token del vocabulario para estar presente en la cadena.\n",
    "            probs = torch.softmax(logits[0, -1, :], dim=-1)\n",
    "            # Simplemente ordenamos por probabilidad de forma descendente\n",
    "            sorted_tokens = torch.argsort(probs, dim=-1, descending=True)\n",
    "\n",
    "            # Utilizamos una politica tipo e-greedy para obtener el siguiente token de la secuencia\n",
    "            # Un eps>=1 quiere decir que siempre se va seleccionar el token de forma 'greedy', es decir\n",
    "            # siempre se toma el token con probabilidad más alta.\n",
    "\n",
    "            # Un eps=0 quiere decir que siempre se va a muestrear el siguiente token en función\n",
    "            # de las probabilidades de cada token\n",
    "\n",
    "            # Un 0<eps<1 va a balancear de forma binomial entre tomar el token con la\n",
    "            # probabilidad más alta y muestrear el token en función de sus probabilidades. \n",
    "            if np.random.random_sample(1)[0] < eps:\n",
    "                # Se toma el mejor token\n",
    "                next_token = sorted_tokens[0].unsqueeze(dim=0)\n",
    "            else:\n",
    "                # Se muetrea el token de la probabilidad de distribución\n",
    "                next_token = torch.multinomial(probs, 1)\n",
    "            \n",
    "            if return_iterations:\n",
    "                # Mantenemos pista de todas las iteraciones para análisis\n",
    "                iteration = {'input': ''.join(output)}\n",
    "                best_n = sorted_tokens[:top_n].cpu().tolist()\n",
    "                choices = {f'Choice #{choice+1}': f'{tokenizer.decode(token)} ({prob:.4f})' for choice, (token, prob) in enumerate(zip(best_n, probs[best_n].cpu().tolist()))}\n",
    "                iteration.update(choices)\n",
    "                iterations.append(iteration)\n",
    "\n",
    "            output.append(tokenizer.decode(next_token))\n",
    "            input_ids = torch.cat([input_ids, next_token.unsqueeze(dim=0)], dim=-1)\n",
    "\n",
    "        output_text = ''.join(output)\n",
    "        if not return_iterations:\n",
    "            return output_text, None\n",
    "        else:\n",
    "            df = pd.DataFrame(iterations)\n",
    "            return output_text, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba98f34-26fc-4f8d-9340-99950a1cdba1",
   "metadata": {},
   "source": [
    "Ahora observemos que pasa cuando generamos texto con nuestra función y algunos parámetros.\n",
    "\n",
    "Primero, observemos que pasa cuando pasamos un `eps=1` que quiere decir que la generación va a ser de tipo greedy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a476e165-88bd-4612-8a85-38187028cae6",
   "metadata": {
    "id": "fb55237d-097d-4db1-8d50-8d9038ea5db6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As part of MIT course 6S099, Artificial General Intelligence, we are going to explore the concept of ��artificial general intelligence�\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>Choice #1</th>\n",
       "      <th>Choice #2</th>\n",
       "      <th>Choice #3</th>\n",
       "      <th>Choice #4</th>\n",
       "      <th>Choice #5</th>\n",
       "      <th>Choice #6</th>\n",
       "      <th>Choice #7</th>\n",
       "      <th>Choice #8</th>\n",
       "      <th>Choice #9</th>\n",
       "      <th>Choice #10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>we (0.2656)</td>\n",
       "      <td>students (0.1552)</td>\n",
       "      <td>I (0.0704)</td>\n",
       "      <td>the (0.0574)</td>\n",
       "      <td>a (0.0297)</td>\n",
       "      <td>you (0.0232)</td>\n",
       "      <td>Professor (0.0170)</td>\n",
       "      <td>our (0.0143)</td>\n",
       "      <td>this (0.0111)</td>\n",
       "      <td>researchers (0.0107)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>are (0.1241)</td>\n",
       "      <td>will (0.0959)</td>\n",
       "      <td>� (0.0899)</td>\n",
       "      <td>have (0.0875)</td>\n",
       "      <td>were (0.0195)</td>\n",
       "      <td>present (0.0182)</td>\n",
       "      <td>use (0.0174)</td>\n",
       "      <td>designed (0.0150)</td>\n",
       "      <td>asked (0.0141)</td>\n",
       "      <td>'ve (0.0133)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>going (0.1412)</td>\n",
       "      <td>studying (0.0660)</td>\n",
       "      <td>exploring (0.0427)</td>\n",
       "      <td>asked (0.0319)</td>\n",
       "      <td>investigating (0.0308)</td>\n",
       "      <td>building (0.0307)</td>\n",
       "      <td>now (0.0305)</td>\n",
       "      <td>working (0.0295)</td>\n",
       "      <td>interested (0.0292)</td>\n",
       "      <td>using (0.0266)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>to (0.9735)</td>\n",
       "      <td>through (0.0095)</td>\n",
       "      <td>over (0.0038)</td>\n",
       "      <td>\\n (0.0021)</td>\n",
       "      <td>on (0.0013)</td>\n",
       "      <td>into (0.0010)</td>\n",
       "      <td>back (0.0009)</td>\n",
       "      <td>deep (0.0006)</td>\n",
       "      <td>explore (0.0005)</td>\n",
       "      <td>for (0.0003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>explore (0.1124)</td>\n",
       "      <td>be (0.0773)</td>\n",
       "      <td>look (0.0617)</td>\n",
       "      <td>learn (0.0598)</td>\n",
       "      <td>build (0.0586)</td>\n",
       "      <td>study (0.0550)</td>\n",
       "      <td>use (0.0515)</td>\n",
       "      <td>discuss (0.0491)</td>\n",
       "      <td>talk (0.0254)</td>\n",
       "      <td>take (0.0220)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>the (0.3220)</td>\n",
       "      <td>how (0.0918)</td>\n",
       "      <td>a (0.0813)</td>\n",
       "      <td>some (0.0704)</td>\n",
       "      <td>what (0.0414)</td>\n",
       "      <td>an (0.0186)</td>\n",
       "      <td>one (0.0158)</td>\n",
       "      <td>machine (0.0146)</td>\n",
       "      <td>two (0.0126)</td>\n",
       "      <td>artificial (0.0114)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>concept (0.0940)</td>\n",
       "      <td>idea (0.0676)</td>\n",
       "      <td>question (0.0344)</td>\n",
       "      <td>topic (0.0340)</td>\n",
       "      <td>field (0.0289)</td>\n",
       "      <td>notion (0.0193)</td>\n",
       "      <td>following (0.0181)</td>\n",
       "      <td>relationship (0.0177)</td>\n",
       "      <td>problem (0.0170)</td>\n",
       "      <td>concepts (0.0156)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>of (0.9646)</td>\n",
       "      <td>and (0.0152)</td>\n",
       "      <td>that (0.0073)</td>\n",
       "      <td>, (0.0013)</td>\n",
       "      <td>behind (0.0008)</td>\n",
       "      <td>called (0.0008)</td>\n",
       "      <td>artificial (0.0007)</td>\n",
       "      <td>Artificial (0.0007)</td>\n",
       "      <td>in (0.0007)</td>\n",
       "      <td>known (0.0006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>� (0.0651)</td>\n",
       "      <td>a (0.0564)</td>\n",
       "      <td>AI (0.0433)</td>\n",
       "      <td>artificial (0.0381)</td>\n",
       "      <td>Artificial (0.0349)</td>\n",
       "      <td>general (0.0324)</td>\n",
       "      <td>self (0.0263)</td>\n",
       "      <td>intelligence (0.0245)</td>\n",
       "      <td>an (0.0223)</td>\n",
       "      <td>the (0.0208)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>� (0.8114)</td>\n",
       "      <td>� (0.1840)</td>\n",
       "      <td>� (0.0019)</td>\n",
       "      <td>� (0.0012)</td>\n",
       "      <td>� (0.0010)</td>\n",
       "      <td>� (0.0001)</td>\n",
       "      <td>� (0.0001)</td>\n",
       "      <td>� (0.0000)</td>\n",
       "      <td>� (0.0000)</td>\n",
       "      <td>� (0.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>art (0.0616)</td>\n",
       "      <td>self (0.0226)</td>\n",
       "      <td>em (0.0216)</td>\n",
       "      <td>Art (0.0199)</td>\n",
       "      <td>super (0.0197)</td>\n",
       "      <td>int (0.0188)</td>\n",
       "      <td>general (0.0175)</td>\n",
       "      <td>AI (0.0135)</td>\n",
       "      <td>Super (0.0133)</td>\n",
       "      <td>aut (0.0133)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>ificial (0.9912)</td>\n",
       "      <td>ific (0.0053)</td>\n",
       "      <td>if (0.0009)</td>\n",
       "      <td>� (0.0006)</td>\n",
       "      <td>ic (0.0004)</td>\n",
       "      <td>ef (0.0003)</td>\n",
       "      <td>ifact (0.0002)</td>\n",
       "      <td>. (0.0001)</td>\n",
       "      <td>- (0.0001)</td>\n",
       "      <td>istic (0.0001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>general (0.2034)</td>\n",
       "      <td>consciousness (0.2032)</td>\n",
       "      <td>life (0.0933)</td>\n",
       "      <td>intelligence (0.0652)</td>\n",
       "      <td>super (0.0402)</td>\n",
       "      <td>� (0.0239)</td>\n",
       "      <td>neural (0.0159)</td>\n",
       "      <td>morality (0.0096)</td>\n",
       "      <td>human (0.0094)</td>\n",
       "      <td>moral (0.0093)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>intelligence (0.9591)</td>\n",
       "      <td>- (0.0070)</td>\n",
       "      <td>intellig (0.0030)</td>\n",
       "      <td>purpose (0.0014)</td>\n",
       "      <td>ization (0.0013)</td>\n",
       "      <td>agents (0.0010)</td>\n",
       "      <td>consciousness (0.0010)</td>\n",
       "      <td>intelligent (0.0009)</td>\n",
       "      <td>human (0.0007)</td>\n",
       "      <td>knowledge (0.0007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>� (0.7337)</td>\n",
       "      <td>. (0.1639)</td>\n",
       "      <td>, (0.0509)</td>\n",
       "      <td>( (0.0288)</td>\n",
       "      <td>\" (0.0070)</td>\n",
       "      <td>\". (0.0033)</td>\n",
       "      <td>.\" (0.0030)</td>\n",
       "      <td>: (0.0012)</td>\n",
       "      <td>or (0.0007)</td>\n",
       "      <td>,\" (0.0007)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input               Choice #1  \\\n",
       "0   As part of MIT course 6S099, Artificial Genera...             we (0.2656)   \n",
       "1   As part of MIT course 6S099, Artificial Genera...            are (0.1241)   \n",
       "2   As part of MIT course 6S099, Artificial Genera...          going (0.1412)   \n",
       "3   As part of MIT course 6S099, Artificial Genera...             to (0.9735)   \n",
       "4   As part of MIT course 6S099, Artificial Genera...        explore (0.1124)   \n",
       "5   As part of MIT course 6S099, Artificial Genera...            the (0.3220)   \n",
       "6   As part of MIT course 6S099, Artificial Genera...        concept (0.0940)   \n",
       "7   As part of MIT course 6S099, Artificial Genera...             of (0.9646)   \n",
       "8   As part of MIT course 6S099, Artificial Genera...              � (0.0651)   \n",
       "9   As part of MIT course 6S099, Artificial Genera...              � (0.8114)   \n",
       "10  As part of MIT course 6S099, Artificial Genera...            art (0.0616)   \n",
       "11  As part of MIT course 6S099, Artificial Genera...        ificial (0.9912)   \n",
       "12  As part of MIT course 6S099, Artificial Genera...        general (0.2034)   \n",
       "13  As part of MIT course 6S099, Artificial Genera...   intelligence (0.9591)   \n",
       "14  As part of MIT course 6S099, Artificial Genera...              � (0.7337)   \n",
       "\n",
       "                  Choice #2            Choice #3               Choice #4  \\\n",
       "0         students (0.1552)           I (0.0704)            the (0.0574)   \n",
       "1             will (0.0959)           � (0.0899)           have (0.0875)   \n",
       "2         studying (0.0660)   exploring (0.0427)          asked (0.0319)   \n",
       "3          through (0.0095)        over (0.0038)             \\n (0.0021)   \n",
       "4               be (0.0773)        look (0.0617)          learn (0.0598)   \n",
       "5              how (0.0918)           a (0.0813)           some (0.0704)   \n",
       "6             idea (0.0676)    question (0.0344)          topic (0.0340)   \n",
       "7              and (0.0152)        that (0.0073)              , (0.0013)   \n",
       "8                a (0.0564)          AI (0.0433)     artificial (0.0381)   \n",
       "9                � (0.1840)           � (0.0019)              � (0.0012)   \n",
       "10            self (0.0226)          em (0.0216)            Art (0.0199)   \n",
       "11            ific (0.0053)          if (0.0009)              � (0.0006)   \n",
       "12   consciousness (0.2032)        life (0.0933)   intelligence (0.0652)   \n",
       "13               - (0.0070)    intellig (0.0030)        purpose (0.0014)   \n",
       "14               . (0.1639)           , (0.0509)              ( (0.0288)   \n",
       "\n",
       "                  Choice #5           Choice #6                Choice #7  \\\n",
       "0                a (0.0297)        you (0.0232)       Professor (0.0170)   \n",
       "1             were (0.0195)    present (0.0182)             use (0.0174)   \n",
       "2    investigating (0.0308)   building (0.0307)             now (0.0305)   \n",
       "3               on (0.0013)       into (0.0010)            back (0.0009)   \n",
       "4            build (0.0586)      study (0.0550)             use (0.0515)   \n",
       "5             what (0.0414)         an (0.0186)             one (0.0158)   \n",
       "6            field (0.0289)     notion (0.0193)       following (0.0181)   \n",
       "7           behind (0.0008)     called (0.0008)      artificial (0.0007)   \n",
       "8       Artificial (0.0349)    general (0.0324)            self (0.0263)   \n",
       "9                � (0.0010)          � (0.0001)               � (0.0001)   \n",
       "10           super (0.0197)        int (0.0188)         general (0.0175)   \n",
       "11              ic (0.0004)         ef (0.0003)           ifact (0.0002)   \n",
       "12           super (0.0402)          � (0.0239)          neural (0.0159)   \n",
       "13         ization (0.0013)     agents (0.0010)   consciousness (0.0010)   \n",
       "14               \" (0.0070)         \". (0.0033)              .\" (0.0030)   \n",
       "\n",
       "                 Choice #8             Choice #9             Choice #10  \n",
       "0             our (0.0143)         this (0.0111)   researchers (0.0107)  \n",
       "1        designed (0.0150)        asked (0.0141)           've (0.0133)  \n",
       "2         working (0.0295)   interested (0.0292)         using (0.0266)  \n",
       "3            deep (0.0006)      explore (0.0005)           for (0.0003)  \n",
       "4         discuss (0.0491)         talk (0.0254)          take (0.0220)  \n",
       "5         machine (0.0146)          two (0.0126)    artificial (0.0114)  \n",
       "6    relationship (0.0177)      problem (0.0170)      concepts (0.0156)  \n",
       "7      Artificial (0.0007)           in (0.0007)         known (0.0006)  \n",
       "8    intelligence (0.0245)           an (0.0223)           the (0.0208)  \n",
       "9               � (0.0000)            � (0.0000)             � (0.0000)  \n",
       "10             AI (0.0135)        Super (0.0133)           aut (0.0133)  \n",
       "11              . (0.0001)            - (0.0001)         istic (0.0001)  \n",
       "12       morality (0.0096)        human (0.0094)         moral (0.0093)  \n",
       "13    intelligent (0.0009)        human (0.0007)     knowledge (0.0007)  \n",
       "14              : (0.0012)           or (0.0007)            ,\" (0.0007)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text, iterations_df = generate(model, tokenizer, text, max_length=15, eps=1.0, top_n=10, return_iterations=True, device=device)\n",
    "print(output_text)\n",
    "iterations_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fb81ac-2dec-44ca-a289-40abc66f20fc",
   "metadata": {},
   "source": [
    "Observamos como el input progresa a la vez que las opciones de tokens que hay. Sin importar cuantas veces invoquemos a la función con los mismos parámetros, siempre vamos a obtener los mismos resultados.\n",
    "\n",
    "Ahora, observemos que pasa si introducimos exploración al reducir el `eps=0.5`, lo cual nos dice que aproximadamente la mitad de las veces va a elegir el siguiente token muestreando y la otra mitad explotando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77b01b10-52a5-4133-a552-1df11138a136",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output_text, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(output_text)\n",
      "Cell \u001b[1;32mIn[19], line 18\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(model, tokenizer, start, max_length, eps, top_n, return_iterations, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Tomamos los logits producidos por la última capa del modelo\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Estos corresponden al siguiente token por cada posición de la cadena\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Por lo tanto, el que nos interesa es el último, que correspondería a la\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# predicción del siguiente token después del final de la cadena original\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# A este aplicamos un softmax para obtener las probabilidades por cada\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# token del vocabulario para estar presente en la cadena.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:975\u001b[0m, in \u001b[0;36mGPTNeoForCausalLM.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    973\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 975\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    990\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:843\u001b[0m, in \u001b[0;36mGPTNeoModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    833\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    834\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    835\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    840\u001b[0m         output_attentions,\n\u001b[0;32m    841\u001b[0m     )\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 843\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:585\u001b[0m, in \u001b[0;36mGPTNeoBlock.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    583\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    584\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(hidden_states)\n\u001b[1;32m--> 585\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[0;32m    587\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:545\u001b[0m, in \u001b[0;36mGPTNeoMLP.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    543\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(hidden_states)\n\u001b[0;32m    544\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(hidden_states)\n\u001b[1;32m--> 545\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m(hidden_states)\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1915\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[0;32m   1914\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[1;32m-> 1915\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1916\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m   1917\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_text, _ = generate(model, tokenizer, text, max_length=1000, eps=0.5, device=device)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "id": "28"
   },
   "source": [
    "### 3. Generando texto con las utilidades del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "29"
   },
   "source": [
    "Ahora, la clase de Huggingface implementa la función `generate` que hace la labor de generación por nosotros, incluyendo las opciones de muestreo y explotación como hemos observado. Solo que además permite otra serie de parámetros y opciones para controlar la generación de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4717a0ac-3717-4d5b-a858-d6763cd859cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(tokens, pad_token_id=tokenizer.eos_token_id, max_length=1000, do_sample=True, temperature=0.5, top_k=0)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0bf6ea-a2bb-4276-b355-9e2083eda65f",
   "metadata": {
    "id": "6e0bf6ea-a2bb-4276-b355-9e2083eda65f"
   },
   "source": [
    "### 4. Carga de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56251dff-d7d1-42dc-82d8-4cafa039d2dd",
   "metadata": {
    "id": "56251dff-d7d1-42dc-82d8-4cafa039d2dd"
   },
   "source": [
    "Ahora, intentemos hacer fine tuning a nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7b6c2ae-c471-467f-a22d-08363a8e36b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "dd378a92a2d64c5b8c3dc014d0ae88a6",
      "861c43fa5f90467f93e1a72482e55d72",
      "0a4e2e0022a644499d568c86bd9c1817",
      "5efcb5095ae2497e9e086c6471f1e58a",
      "f822a04d06dc4115bcd9aa3e4f25025b",
      "872afb9e72ef4d3c84bc2ac03e2c4b04",
      "8d010fc8619d44f4b203f7082fe953d3",
      "fc65e3fc1c4a4593bc232fd82cdaf0d0",
      "0ada96787b384a6cb2c31b1fb9c64e8d",
      "ab43505402cd45ab977986a299dc4015",
      "27165f0fc4b848b782c5e23b2f51781a"
     ]
    },
    "id": "a7b6c2ae-c471-467f-a22d-08363a8e36b6",
    "outputId": "4d5ec8ec-6a71-409e-a96e-7a60db8e1f31"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd378a92a2d64c5b8c3dc014d0ae88a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"RamAnanth1/lex-fridman-podcasts\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3f821-996a-4ada-9cb4-b1c50765c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58999edc-3464-4fe1-8e02-f0248ac6ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format('pandas')\n",
    "df = dataset['train'].to_pandas()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b3e787-8e66-44a8-99f6-992434b500bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Palabras por podcast'] = df['captions'].str.split().apply(len)\n",
    "df['Palabras por podcast'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e859f-2e2f-4f33-b5cd-2a50c51ba71f",
   "metadata": {},
   "source": [
    "### 5. Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00001f0a-87de-43c6-b2ae-d9c94f778883",
   "metadata": {},
   "source": [
    "Aquí podemos observar que la mediana de longitud en terminos de palabras es de 31. Esto es esperado, pues los chistes deben ser cortos por naturaleza. Por otra parte, es bastante claro que el corpus original del modelo pre-entrenado contenía texto muy diferente a este, por lo que la calidad de los resultados, sin hacer mayores modificaciones puede que no sea buena.\n",
    "\n",
    "Ahora, prepararémos el conjunto de datos para entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58300f97-fb72-474c-8135-938f2673da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(max_len):\n",
    "    def _preprocess_function(examples):\n",
    "        return tokenizer(examples['text'], max_length=max_len, truncation=True, padding='max_length')\n",
    "    return _preprocess_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec571bbe-43be-425f-bd5e-c7904e8f5ab5",
   "metadata": {},
   "source": [
    "Los modelos GPT no esperan otra cosa más que los `input_ids`, por lo que retirarémos todas las demás columnas del dataset ya que no nos son de utilidad en este momento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba16ac-6c6b-4423-8cbc-6585847769fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_format()\n",
    "tokenized_dataset = dataset['train'].map(preprocess_function(max_len=512), batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([col for col in tokenized_dataset.column_names if col != 'input_ids'])\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(train_size=0.9)\n",
    "tokenized_dataset.set_format('torch')\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4119c4a6-d90b-4e4e-bdfd-993bfb11334a",
   "metadata": {},
   "source": [
    "Finalmente procedemos a definir el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a337587-ae60-48f0-b3c7-065d950605eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8 if IN_COLAB else 2\n",
    "logging_steps = len(tokenized_dataset['train']) // batch_size\n",
    "# Definimos los parámetros globales de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./hf-gpt',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "# Y definimos el entrenador, especificando el modelo, datasets y el tokenizador\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f68b82-4760-4d6f-9e73-0f43574f2b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ce5b2-865e-4495-a2f8-a79e7174c7dd",
   "metadata": {},
   "source": [
    "### 6. Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59fc7d-626c-4941-a1c7-e34e019ba2be",
   "metadata": {},
   "source": [
    "Ahora observemos los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd3a04-1cea-4cbd-ae48-6d7985fb8380",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(tokens, pad_token_id=tokenizer.eos_token_id, max_length=1000, do_sample=True, temperature=0.8)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278ca09-2779-4a24-8227-6cfd878d8317",
   "metadata": {},
   "source": [
    "No parece ser muy gracioso precisamente, sin embargo, notemos que la generación de texto cambia de \"estilo\", ahora es mucho más frecuente encontrar conversaciones cortas, frases concisas, y situaciones particulares, en lugar del estilo más literario del modelo original. Esto es un indicio de la influencia que tiene el conjunto de datos de entrenamiento en el modelo final, esto es algo a tener muy en cuenta a la hora de utilizar y hacer fine tuning a modelos de lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {
    "id": "54"
   },
   "source": [
    "### 7. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {
    "id": "55"
   },
   "source": [
    "#### Eficacia del flujo de análisis\n",
    "\n",
    "- Al comparar arquitecturas de modelos de lenguaje como BERT y GPT, se identifican similitudes en su capacidad de generar representaciones ricas del lenguaje, algunas diferencias clave en su estructura y en su proceso de entrenamiento.\n",
    "\n",
    "- Ambos modelos demuestran que un pre-entrenamiento sólido y la construcción de embeddings de alta calidad son factores críticos para alcanzar buenos resultados en tareas posteriores, evitando costos de entrenamiento desde cero.\n",
    "\n",
    "#### Rendimiento del modelo\n",
    "\n",
    "- Tanto BERT como GPT pueden adaptarse a una amplia variedad de tareas posteriores (clasificación, generación de texto, análisis semántico, etc.), lo que valida la versatilidad de los enfoques de transfer learning y fine tuning.\n",
    "\n",
    "- La elección del modelo y la estrategia de entrenamiento depende de la tarea: BERT sobresale en comprensión y análisis de contexto bidireccional, mientras que GPT destaca en generación de texto coherente y fluido.\n",
    "\n",
    "#### Limitaciones observadas\n",
    "\n",
    "- Los modelos generativos enfrentan un dilema de exploración–explotación: una decodificación enfocada en la explotación (p. ej. greedy search) brinda mayor precisión pero tiende a producir textos monótonos; en cambio, la exploración (p. ej. sampling con temperatura alta) promueve creatividad y diversidad, pero con riesgo de incoherencia o “alucinaciones”.\n",
    "\n",
    "- La calidad del modelo depende en gran medida de los datos de entrenamiento. Conjuntos de datos sesgados, poco representativos o de baja calidad pueden degradar el desempeño e introducir sesgos o errores difíciles de corregir.\n",
    "\n",
    "#### Áreas de mejora\n",
    "\n",
    "- Profundizar en la selección y curaduría de datasets, asegurando diversidad, equilibrio y relevancia para el dominio de aplicación.\n",
    "\n",
    "- Experimentar con estrategias de decodificación y con la afinación de hiperparámetros para encontrar el punto óptimo entre creatividad, coherencia y precisión.\n",
    "\n",
    "- Explorar técnicas de optimización y compresión que permitan desplegar modelos grandes en entornos de recursos limitados.\n",
    "\n",
    "#### Valor práctico\n",
    "\n",
    "- La adopción de modelos pre-entrenados como GPT ofrece una base sólida y flexible para proyectos de NLP, equilibrando costo, tiempo y calidad.\n",
    "\n",
    "- El entendimiento de los trade-offs entre exploración y explotación, así como la adecuada selección de datos y métodos de decodificación, es esencial para alinear el modelo con los objetivos específicos del negocio y minimizar riesgos de sesgos o resultados no deseados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1089b9-ae81-4ae0-91ec-d323c7c84352",
   "metadata": {
    "id": "4b1089b9-ae81-4ae0-91ec-d323c7c84352"
   },
   "source": [
    "### 8. Apendice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a28e4-5609-4f01-b6f9-60343d6cb413",
   "metadata": {
    "id": "636a28e4-5609-4f01-b6f9-60343d6cb413"
   },
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "libs = [\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"datasets\",\n",
    "    \"torch\",\n",
    "    \"pytorch-lightning\",\n",
    "    \"torchmetrics\",\n",
    "    \"tqdm\",\n",
    "    \"transformers\",\n",
    "    \"scikit-learn\"\n",
    "]\n",
    "\n",
    "for lib in libs:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(lib).version\n",
    "        print(f\"{lib}=={version}\")\n",
    "    except Exception:\n",
    "        print(f\"{lib}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646eaeca-8b47-46c4-9995-16c1f2ceb0e0",
   "metadata": {
    "id": "646eaeca-8b47-46c4-9995-16c1f2ceb0e0"
   },
   "outputs": [],
   "source": [
    " ## Solo correr en local\n",
    "\n",
    "# import nbformat\n",
    "\n",
    "## Cargar notebook\n",
    "# with open(\"nlp_with_bert.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    # nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "## Eliminar widgets corruptos si existen\n",
    "# if \"widgets\" in nb[\"metadata\"]:\n",
    "    # del nb[\"metadata\"][\"widgets\"]\n",
    "\n",
    "## Guardar reparado\n",
    "# with open(\"nlp_with_bert.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
    "    # nbformat.write(nb, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
